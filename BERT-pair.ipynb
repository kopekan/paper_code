{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#require: pandas, tensorflow_hub, tensorflow_text, tensorflow_addons, sklearn\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras\n",
    "import tensorflow_text as text  # Imports TF ops for preprocessing.\n",
    "import model.tokenization as tokenization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping,CSVLogger\n",
    "from tensorflow.keras.layers import Input, Dense,Dropout,Embedding,LSTM,Bidirectional, Masking, TimeDistributed, Conv1D, MaxPooling1D, Flatten, concatenate, GRU\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "BERT_src = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\"\n",
    "BERT_src = 'https://tfhub.dev/tensorflow/bert_zh_L-12_H-768_A-12/3'#'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/4' \n",
    "BERT_LAYER = hub.KerasLayer(BERT_src, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = ['功能', '品質','配件','售後','外觀','價位','音量', '無']\n",
    "cate2idx = {cate:idx for idx, cate in enumerate(category)}\n",
    "idx2cate = {idx: cate for cate, idx in cate2idx.items()}\n",
    "sentiment = ['正向', '負向', '中立']\n",
    "sent2idx = {sent:idx for idx, sent in enumerate(sentiment)}\n",
    "idx2sent = {idx: sent for sent, idx in sent2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twoSentence2BERT(inputs, target_, onlytarget=False): #input as list of dictionary\n",
    "#     BERT_LAYER = hub.KerasLayer(BERT_src, trainable=False)\n",
    "    VOCAB_FILE = BERT_LAYER.resolved_object.vocab_file.asset_path.numpy()\n",
    "    tokenizer = tokenization.FullTokenizer(VOCAB_FILE, True) \n",
    "    output={'input_word_ids':[], 'input_mask':[], 'input_type_ids':[]}\n",
    "    for data in inputs:\n",
    "        count = 0\n",
    "        #tokenize origin sentence\n",
    "        tempword, tempmask, temptype=[], [], []\n",
    "        #add cls\n",
    "        tempword.append(tokenizer.convert_tokens_to_ids(['[CLS]'])[0])\n",
    "        tempmask.append(1)\n",
    "        temptype.append(0)\n",
    "        if not onlytarget:\n",
    "            sentence = data['sentence'] #string\n",
    "            tokenize_sentence = tokenizer.tokenize(sentence)\n",
    "            for ts in tokenize_sentence:\n",
    "                try:\n",
    "                    token_id = tokenizer.convert_tokens_to_ids([ts.lower()])\n",
    "                except:\n",
    "                    token_id = tokenizer.convert_tokens_to_ids(['[UNK]'])\n",
    "                tempword.append(token_id[0])\n",
    "                tempmask.append(1)\n",
    "                temptype.append(0)\n",
    "                count+=1\n",
    "            #add sep\n",
    "            if target_:\n",
    "                tempword.append(tokenizer.convert_tokens_to_ids(['[SEP]'])[0])\n",
    "                tempmask.append(1)\n",
    "                temptype.append(0)\n",
    "        if target_:\n",
    "            target = data['target'] #string        \n",
    "            tokenize_target = tokenizer.tokenize(target)        \n",
    "            for tt in tokenize_target:\n",
    "                try:\n",
    "                    token_id = tokenizer.convert_tokens_to_ids([tt.lower()])\n",
    "                except:\n",
    "                    token_id = tokenizer.convert_tokens_to_ids(['[UNK]'])\n",
    "                tempword.append(token_id[0])\n",
    "                tempmask.append(1)\n",
    "                temptype.append(1)\n",
    "                count+=1\n",
    "                if count>=128:\n",
    "                    break\n",
    "        if len(tempword)>127:\n",
    "            tempword=tempword[:127]\n",
    "            tempmask=tempmask[:127]\n",
    "            temptype=temptype[:127]  \n",
    "        #add sep\n",
    "        tempword.append(tokenizer.convert_tokens_to_ids(['[SEP]'])[0])\n",
    "        tempmask.append(1)\n",
    "        temptype.append(1)                \n",
    "        while(len(tempword)<128):\n",
    "            tempword.append(0)\n",
    "            tempmask.append(0)\n",
    "            temptype.append(0)            \n",
    "        output['input_word_ids'].append(tempword)\n",
    "        output['input_mask'].append(tempmask)\n",
    "        output['input_type_ids'].append(temptype)        \n",
    "    return output\n",
    "\n",
    "def BERTdata2Traindata(data, target=True, to_cate=True, file_name):\n",
    "    from tensorflow.keras.utils import to_categorical\n",
    "    outputx = twoSentence2BERT(data, target)\n",
    "    outputy = []\n",
    "    if to_cate:\n",
    "        for d in data:\n",
    "            if 'Sent' in sent:\n",
    "                outputy.append(sent2idx[d['sentiment']])\n",
    "            else:\n",
    "                outputy.append(cate2idx[d['aspect_category']])\n",
    "                    \n",
    "    else:\n",
    "        for d in data:\n",
    "            if 'Sent' in sent:\n",
    "                outputy.append(d['sentiment'])\n",
    "            else:\n",
    "                outputy.append(d['aspect_category'])\n",
    "        \n",
    "    if to_cate:\n",
    "        return outputx, to_categorical(outputy)\n",
    "    else:\n",
    "        return outputx, outputy\n",
    "            \n",
    "        \n",
    "def transBERTtype(data, toBERT=True):\n",
    "    if toBERT: #input 每個資料都有三個key，每個key的維度都是128\n",
    "        return {k:np.array([data[i][k] for i in range(len(data))]) for k in data[0].keys()}\n",
    "    else: #原本BERT的形式\n",
    "        return [{k:data[k][i] for k in data.keys()} for i in range(len(data['input_word_ids']))]        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:1345, test:1422\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "#PB-Sent_BERT_same_aux_NLI-B_train06-16.json\n",
    "file_name = 'PB-Sent_BERT_same_aux_NLI-M'\n",
    "type_ = []\n",
    "BERT_train, BERT_test = [], []\n",
    "with open('./data/homeapp/Sent_data/'+file_name+'_train06-16.json', 'r', encoding='utf8') as file:\n",
    "    data = file.readlines()\n",
    "for d in data:\n",
    "    BERT_train.append(json.loads(d))\n",
    "    \n",
    "with open('./data/homeapp/Sent_data/'+file_name+'_test06-16.json', 'r', encoding='utf8') as file:\n",
    "    data = file.readlines()\n",
    "for d in data:\n",
    "    BERT_test.append(json.loads(d))\n",
    "\n",
    "print('train:{}, test:{}'.format(len(BERT_train), len(BERT_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sentiment only with BN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BERT_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7b187a2022dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mBERT_train_mod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBERT_test_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mBERT_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BERT_train' is not defined"
     ]
    }
   ],
   "source": [
    "#第一部分實驗有提到 用只把產品廠牌(brand name)當成輔助句子的\n",
    "#這邊注意一下變數名字 train/test 我有另外取名\n",
    "\n",
    "BERT_train_mod, BERT_test_mod = [], []\n",
    "for i in BERT_train:\n",
    "    tmp = i.copy()\n",
    "    tmp['target'] = i['target'].split('-')[0]\n",
    "    BERT_train_mod.append(i)\n",
    "for i in BERT_test:\n",
    "    tmp = i.copy()\n",
    "    tmp['target'] = i['target'].split('-')[0]\n",
    "    BERT_test_mod.append(i)\n",
    "BERT_train_mod[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer data into BERT format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_cate: 看要不要轉成category的形式 (e.g. 2 -> [0, 1, 0] 3 -> [0, 0, 1]) \n",
    "#objective: 看現在的主要目標是sentiment 還是 aspect category 再自己設定\n",
    "train_x, train_sentiment = BERTdata2Traindata(BERT_train, to_cate=True, file_name)\n",
    "test_x, test_sentiment = BERTdata2Traindata(BERT_test, to_cate=True, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Reverse Layer\n",
    "@tf.custom_gradient\n",
    "def grad_reverse(x):\n",
    "    y = tf.identity(x)\n",
    "    def custom_grad(dy):\n",
    "        return -dy\n",
    "    return y, custom_grad\n",
    "\n",
    "class GradReverse(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, x):\n",
    "        return grad_reverse(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#這邊要注意一下 對於不同的輔助句子 要用不同的激活函數跟Loss function \n",
    "#多元分類、二元分類 -> categorical crossentropy (我記得這邊如果二元分類 softmax+categorical_crossentropy會跑不出來，只能用categorical)\n",
    "#多元標籤 -> binary crossentropy\n",
    "\n",
    "def create_classify_model(data_size, file_name, batch_size = 16, epochs=10):\n",
    "    if 'Sent' in file_name:\n",
    "        task = 'sentiment'\n",
    "    else:\n",
    "        task = 'aspect_category'\n",
    "    \n",
    "    if '-B' in file_name:\n",
    "        output_len = 2\n",
    "    elif 'Sent' in file_name:\n",
    "        output_len = 3\n",
    "    else:\n",
    "        output_len = 8\n",
    "        \n",
    "    import model.optimization as optimization\n",
    "    input1 = Input(shape=(128,), name='input_word_ids', dtype=tf.int32)\n",
    "    input2 = Input(shape=(128,),name='input_mask', dtype=tf.int32)\n",
    "    input3 = Input(shape=(128,),name='input_type_ids', dtype=tf.int32)\n",
    "    bert_layer = hub.KerasLayer(BERT_src, trainable=True, output_key='pooled_output', name='bert_layer')\n",
    "    output = bert_layer({'input_word_ids':input1, 'input_mask':input2, 'input_type_ids':input3})\n",
    "#     output = Dense(128, name = 'presentation_')(output)\n",
    "    \n",
    "    output = Dense(64, activation='relu', name = task+'pre', \n",
    "                             kernel_initializer=keras.initializers.glorot_normal(0), bias_initializer='zeros')(output)\n",
    "#     sentiment_output = Dropout(0.2, name='sentiment_drop')(output)\n",
    "    if output_len!=8:\n",
    "        output = Dense(output_len, activation='softmax', name = task, \n",
    "                                 kernel_initializer=keras.initializers.glorot_normal(0), bias_initializer='zeros')(output) #softmax會讓所有的output總和=1\n",
    "    else:\n",
    "        output = Dense(output_len, activation='sigmoid', name = 'aspect_category', \n",
    "                                 kernel_initializer=keras.initializers.glorot_normal(0), bias_initializer='zeros')(output) #softmax會讓所有的output總和=1\n",
    "        \n",
    "    \n",
    "    output_model = Model(inputs = [input1, input2, input3], outputs = sentiment_output)\n",
    "    optimizer = optimization.create_optimizer(\n",
    "    5e-5, (data_size//batch_size)*epochs, int((epochs*data_size*0.1)//batch_size), 0.0, 'adamw')\n",
    "    if output_len!=8:\n",
    "        output_model.compile(optimizer=optimizer, \n",
    "                             loss={task:'categorical_crossentropy'})})\n",
    "    else:\n",
    "        output_model.compile(optimizer=optimizer, \n",
    "                             loss={task:'binary_crossentropy'})})\n",
    "        \n",
    "    return output_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 其他設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def sample_data_(data_list, datasize, random_=True):\n",
    "    #data_list = [BERT_x, sentiment, (category)]\n",
    "    if random_:\n",
    "        samples = random.sample(range(len(data_list[1])), datasize)\n",
    "    else:\n",
    "        samples = list(range(datasize))        \n",
    "    bert_x = data_list[0]\n",
    "    bert_x = {k:np.array([bert_x[k][i] for i in samples]) for k in bert_x.keys()}\n",
    "    sentiment = np.array(data_list[1])\n",
    "    sentiment = np.array([sentiment[i] for i in samples])\n",
    "    if len(data_list)>2:\n",
    "        category = np.array(data_list[2])\n",
    "        category = np.array([category[i] for i in samples])\n",
    "        return bert_x, sentiment, category\n",
    "    else:\n",
    "        return bert_x, sentiment\n",
    "def sample_data(data_list, datasize, random_=True):\n",
    "    #data_list = [BERT_x, sentiment]\n",
    "    if random_:\n",
    "        samples = random.sample(range(len(data_list[1])), datasize)\n",
    "    else:\n",
    "        samples = list(range(datasize))        \n",
    "    bert_x = data_list[0]\n",
    "    bert_x = {k:np.array([bert_x[k][i] for i in samples]) for k in bert_x.keys()}\n",
    "    sentiment = np.array(data_list[1])\n",
    "    sentiment = np.array([sentiment[i] for i in samples])\n",
    "    return bert_x, sentiment\n",
    "def model_get_weight(model, keyword='', not_=False):\n",
    "    origin_weight = []\n",
    "    for layer in model.layers:\n",
    "        if not_:\n",
    "            if not layer.name.startswith(keyword): \n",
    "                origin_weight.append(np.array(layer.get_weights()))\n",
    "        else:\n",
    "            if layer.name.startswith(keyword): \n",
    "                origin_weight.append(np.array(layer.get_weights()))\n",
    "    return np.array(origin_weight)\n",
    "\n",
    "def update_weights(model, update_weight, keyword='', not_=False):\n",
    "    k=0\n",
    "    for layer in model.layers:\n",
    "        if not_:\n",
    "            if not layer.name.startswith(keyword):\n",
    "                layer.set_weights(update_weight[k])\n",
    "                k+=1\n",
    "        else:\n",
    "            if layer.name.startswith(keyword):\n",
    "                layer.set_weights(update_weight[k])\n",
    "                k+=1\n",
    "def update_weights_forsame(model, model_src):\n",
    "    for layer in model.layers:\n",
    "        flag = False\n",
    "        for layer_src in model_src.layers:\n",
    "            if layer.name==layer_src.name and len(layer.get_weights())==len(layer_src.get_weights()) and flag==False:\n",
    "                try: \n",
    "                    layer.set_weights(layer_src.get_weights())\n",
    "                    flag = True\n",
    "                except:\n",
    "                    print('error!')\n",
    "        if flag==False:\n",
    "            print('model layer: \"', layer.name, '\" not in source model')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model...\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "import model.optimization as optimization\n",
    "try:\n",
    "    del tmp_model\n",
    "except:\n",
    "    ;\n",
    "src_model = 'rep_adv.h5'\n",
    "data_size=1000\n",
    "batch_size=32\n",
    "epochs=7\n",
    "optimizer = optimization.create_optimizer(5e-5, (data_size//batch_size)*epochs, int((epochs*data_size*0.1)//batch_size), 0.0, 'adamw')\n",
    "from tensorflow.keras.models import load_model\n",
    "print('loading model...')\n",
    "tmp_model = load_model('./Meta-ACS_weight_save/'+src_model, custom_objects={'KerasLayer':BERT_LAYER, 'AdamWeightDecay':optimizer})\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "meta這個變數是看要不要用已讀取的pretrain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1/7\n",
      "85/85 [==============================] - 34s 251ms/step - loss: 1.2222\n",
      "Epoch 2/7\n",
      "85/85 [==============================] - 21s 252ms/step - loss: 0.7696\n",
      "Epoch 3/7\n",
      "85/85 [==============================] - 21s 253ms/step - loss: 0.5575\n",
      "Epoch 4/7\n",
      "85/85 [==============================] - 22s 253ms/step - loss: 0.4321\n",
      "Epoch 5/7\n",
      "85/85 [==============================] - 22s 254ms/step - loss: 0.3314\n",
      "Epoch 6/7\n",
      "85/85 [==============================] - 22s 255ms/step - loss: 0.2393\n",
      "Epoch 7/7\n",
      "85/85 [==============================] - 22s 256ms/step - loss: 0.2092\n",
      "ma-micro: 0.6946830640599477\n",
      "micro: 0.7433192686357243\n",
      "spend: 180\n",
      "1422\n"
     ]
    }
   ],
   "source": [
    "# train_x, train_sentiment\n",
    "# test_x, test_sentiment\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report, precision_recall_fscore_support\n",
    "\n",
    "import time\n",
    "meta = False\n",
    "epochs = 7\n",
    "sent_pred_total = []\n",
    "mamicro = []\n",
    "micros = []\n",
    "for itr in range(1): #看要重複跑幾次實驗\n",
    "    starttime = time.time()\n",
    "    print(itr)\n",
    "    try:\n",
    "        del model\n",
    "    except:\n",
    "        ;\n",
    "    x, sent = sample_data_([train_x, train_sentiment], datasize=len(train_sentiment),random_=False)\n",
    "    model = create_classify_model(data_size=len(sent), epochs=epochs, sentiment_len = 3)\n",
    "    if meta:\n",
    "        update_weights_forsame(model, tmp_model)    \n",
    "    history = model.fit(x, sent, batch_size=16, epochs=epochs, verbose=1)\n",
    "    sent_pred = model.predict([np.array(test_x['input_word_ids']), \n",
    "                        np.array(test_x['input_mask']),\n",
    "                        np.array(test_x['input_type_ids'])])\n",
    "    sent_predict = [sentiment[np.argmax(i)] for i in sent_pred]\n",
    "    sent_pred_total+=sent_predict\n",
    "    sent_ans = [idx2sent[np.argmax(i)] for i in test_sentiment]\n",
    "    micro = []\n",
    "    for j in category:\n",
    "        pred, ans = [], []\n",
    "        for k in range(1422):\n",
    "            if BERT_test[k]['target'].split('-')[1]==j:\n",
    "                pred.append(sent_predict[k])\n",
    "                ans.append(BERT_test[k]['sentiment'])\n",
    "        micro.append(f1_score(ans, pred, average='micro'))\n",
    "    micros.append(f1_score(sent_ans, sent_predict, average='micro'))\n",
    "    mamicro.append(np.mean(micro))\n",
    "    print('ma-micro:', np.mean(micro))\n",
    "    print('micro:', f1_score(sent_ans, sent_predict, average='micro'))\n",
    "    print('spend:', int(time.time()-starttime), 's')\n",
    "print(len(sent_pred_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate of AC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.1\t0.41101\t0.84249\t0.55249\n",
      "threshold:0.2\t0.49436\t0.70696\t0.58185\n",
      "threshold:0.3\t0.60498\t0.56996\t0.58695\n",
      "threshold:0.4\t0.63636\t0.51282\t0.56795\n",
      "threshold:0.5\t0.66095\t0.47985\t0.55603\n",
      "threshold:0.6\t0.67505\t0.45201\t0.54147\n",
      "threshold:0.7\t0.70303\t0.42491\t0.52968\n",
      "threshold:0.8\t0.74548\t0.36264\t0.48793\n",
      "threshold:0.9\t0.84918\t0.18974\t0.31018\n",
      "功能:0.674\t0.868\t0.758\n",
      "品質:0.5\t0.005\t0.01\n",
      "配件:0.487\t0.487\t0.487\n",
      "售後:0.411\t0.6\t0.488\n",
      "外觀:0.339\t0.328\t0.333\n",
      "價位:0.525\t0.5\t0.512\n",
      "音量:1.0\t0.081\t0.15\n",
      "無:0.622\t0.644\t0.633\n",
      "----avg. macro f1:0.4215550392755408-----------\n"
     ]
    }
   ],
   "source": [
    "#CATEGORY\n",
    "#multiple\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report, precision_recall_fscore_support\n",
    "if '-M' in file_name:\n",
    "    sent_pred = [j for i in sent_pred for j in i]\n",
    "    test_sentiment = [j for i in test_sentiment for j in i ]\n",
    "threds = [.1, .2, .3, .4, .5, .6, .7, .8, .9]\n",
    "max_ = 0.0\n",
    "thrd = 0\n",
    "for thred in threds:\n",
    "    sent_predict = [1 if i>=thred else 0 for i in sent_pred]\n",
    "    p, r, f, _ = precision_recall_fscore_support(test_sentiment, sent_predict, average='binary')\n",
    "    print('threshold:{}\\t p:{}\\t r:{}\\t f1:{}'.format(thred, round(p, 5), round(r, 5), round(f, 5)))\n",
    "    if f>=max_:\n",
    "        max_=f\n",
    "        thrd = thred\n",
    "        \n",
    "sent_predict = [1 if i>=thrd else 0 for i in sent_pred]    \n",
    "acs = []\n",
    "categories = ['功能', '品質','配件','售後','外觀','價位','音量', '無']\n",
    "for i in range(8):\n",
    "    acs.append({'true':0, 'pred':0, 'ans':0})\n",
    "for i in range(len(sent_predict)//8):\n",
    "    for j in range(8):\n",
    "        if test_sentiment[i*8+j]==1:\n",
    "            acs[j]['ans']+=1\n",
    "        if sent_predict[i*8+j]==1:\n",
    "            acs[j]['pred']+=1\n",
    "        if sent_predict[i*8+j]==1 and test_sentiment[i*8+j]==1:\n",
    "            acs[j]['true']+=1\n",
    "f_all = 0\n",
    "print('每個aspect category各自的準確度')\n",
    "for i in range(8):\n",
    "    p = acs[i]['true']/acs[i]['pred']\n",
    "    r = acs[i]['true']/acs[i]['ans']\n",
    "    f = 2*p*r/(p+r)\n",
    "    print('{}: p:{}\\t r:{}\\t f1:{}'.format(categories[i],round(p,3), round(r,3), round(f,3)))\n",
    "    f_all+=f\n",
    "print('----avg. f1:{}-----------'.format(f_all/8))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QA-B CATE  \n",
    "0.59234\t0.68293\t0.63442\n",
    "0.60582\t0.65854\t0.63108\n",
    "0.62117\t0.64206\t0.63144\n",
    "0.6328\t0.62821\t0.6305\n",
    "0.64496\t0.6203\t0.63239\n",
    "0.6478\t0.61107\t0.6289\n",
    "0.65352\t0.60053\t0.6259\n",
    "0.66244\t0.58603\t0.6219\n",
    "0.69032\t0.54515\t0.60921\n",
    "功能:0.7\t0.814\t0.752\n",
    "\n",
    "品質:0.405\t0.559\t0.47\n",
    "\n",
    "配件:0.5\t0.74\t0.597\n",
    "\n",
    "售後:0.528\t0.734\t0.614\n",
    "\n",
    "外觀:0.391\t0.486\t0.433\n",
    "\n",
    "價位:0.429\t0.343\t0.381\n",
    "\n",
    "音量:0.694\t0.829\t0.756\n",
    "\n",
    "無:0.671\t0.667\t0.669\n",
    "----avg. f1:0.5840626999534889-----------  \n",
    "\n",
    "\n",
    "\n",
    "NLI-B CATE  \n",
    "(0.5471421592574499, 0.7382992748846408, 0.6285072951739618, None)  \n",
    "(0.5929203539823009, 0.6624917600527357, 0.6257783312577833, None)  \n",
    "(0.6156330749354005, 0.6282135794330916, 0.6218597063621534, None)  \n",
    "(0.6302864938608458, 0.6090969017798286, 0.6195105598390881, None)  \n",
    "(0.6396848137535817, 0.5886618325642716, 0.6131136285616203, None)  \n",
    "(0.6469248291571754, 0.5616348055372445, 0.6012702893436839, None)  \n",
    "(0.6636661211129297, 0.5346077785102176, 0.5921869295363272, None)  \n",
    "(0.685981308411215, 0.4838497033618985, 0.5674526478546579, None)  \n",
    "(0.7284533648170012, 0.4067237969676994, 0.5219966159052454, None)  \n",
    "\n",
    "\n",
    "NLI-M CATE\n",
    "threshold:0.1\t0.53935\t0.85861\t0.66252\n",
    "threshold:0.2\t0.61089\t0.78095\t0.68553\n",
    "threshold:0.3\t0.64913\t0.74139\t0.6922\n",
    "threshold:0.4\t0.67749\t0.7033\t0.69015\n",
    "threshold:0.5\t0.70367\t0.65934\t0.68079\n",
    "threshold:0.6\t0.72917\t0.61538\t0.66746\n",
    "threshold:0.7\t0.762\t0.56996\t0.65214\n",
    "threshold:0.8\t0.8016\t0.51502\t0.62712\n",
    "threshold:0.9\t0.85255\t0.42784\t0.56976\n",
    "功能:0.731\t0.905\t0.809\n",
    "品質:0.477\t0.629\t0.543\n",
    "配件:0.511\t0.6\t0.552\n",
    "售後:0.548\t0.92\t0.687\n",
    "外觀:0.5\t0.531\t0.515\n",
    "價位:0.63\t0.468\t0.537\n",
    "音量:0.71\t0.595\t0.647\n",
    "無:0.721\t0.731\t0.726\n",
    "----avg. macro f1:0.6268860290191695-----------\n",
    "\n",
    "\n",
    "QA-M CATE\n",
    "threshold:0.1\t0.53996\t0.85128\t0.66079\n",
    "threshold:0.2\t0.60398\t0.77875\t0.68032\n",
    "threshold:0.3\t0.63734\t0.73773\t0.68387\n",
    "threshold:0.4\t0.66643\t0.68791\t0.677\n",
    "threshold:0.5\t0.69345\t0.65128\t0.6717\n",
    "threshold:0.6\t0.7342\t0.62125\t0.67302\n",
    "threshold:0.7\t0.75814\t0.56264\t0.64592\n",
    "threshold:0.8\t0.79677\t0.50549\t0.61856\n",
    "threshold:0.9\t0.85952\t0.41685\t0.56142\n",
    "功能:0.719\t0.887\t0.794\n",
    "品質:0.475\t0.614\t0.535\n",
    "配件:0.457\t0.6\t0.519\n",
    "售後:0.597\t0.8\t0.684\n",
    "外觀:0.534\t0.484\t0.508\n",
    "價位:0.66\t0.565\t0.609\n",
    "音量:0.71\t0.595\t0.647\n",
    "無:0.687\t0.747\t0.716\n",
    "----avg. macro f1:0.6264922851780835-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate of Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 只適用於剛剛預測出的sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此部分是在第一部分實驗時，sentiment任務中 binary output / multiple output 的實驗比較\n",
    "\n",
    "由於兩種方式的輸出略有不同，因此要evaluate方式會有些微差異"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment accuracy: 0.7481012658227848\n",
      "sentiment f1 score(macro): 0.6937461105584766\n",
      "sentiment f1 score(micro): 0.7481012658227848\n",
      "sentiment f1 score(weight): 0.741133191601366\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          中立       0.78      0.88      0.83      3940\n",
      "          正向       0.72      0.59      0.65      2205\n",
      "          負向       0.65      0.57      0.61       965\n",
      "\n",
      "    accuracy                           0.75      7110\n",
      "   macro avg       0.72      0.68      0.69      7110\n",
      "weighted avg       0.74      0.75      0.74      7110\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-1efa4be232d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mBERT_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_ans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mpredict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_predict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#Multiple\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report, precision_recall_fscore_support\n",
    "\n",
    "# sent_predict = [sentiment[np.argmax(i)] for i in sent_pred]\n",
    "# sent_ans = [sentiment[np.argmax(i)] for i in test_sentiment]\n",
    "if '-B' in file_name:\n",
    "    for i in range(int(len(test_sentiment)/3)):\n",
    "        sent_predict.append(sentiments[np.argmax([sent_pred[i*3][0], sent_pred[i*3+1][0], sent_pred[i*3+2][0]])])\n",
    "        sent_ans.append(sentiments[np.argmax([test_sentiment[i*3], test_sentiment[i*3+1], test_sentiment[i*3+2]])])\n",
    "else:\n",
    "    sent_predict = sent_pred_total\n",
    "    sent_ans = [sentiment[np.argmax(i)] for i in test_sentiment]\n",
    "    \n",
    "print('sentiment f1 score(macro):', f1_score(sent_ans, sent_predict, average='macro'))\n",
    "print('sentiment f1 score(micro):', f1_score(sent_ans, sent_predict, average='micro'))\n",
    "print('sentiment f1 score(weight):', f1_score(sent_ans, sent_predict, average='weighted'))\n",
    "print(classification_report(sent_ans, sent_predict))\n",
    "predict, answer = [], []\n",
    "for i in range(8):\n",
    "    predict.append([])\n",
    "    answer.append([])\n",
    "for d in range(len(sent_predict)):\n",
    "    flag = True\n",
    "    for c in range(len(category)):\n",
    "        if category[c] in BERT_test[d]['target'] and flag:\n",
    "            answer[c].append(sent_ans[d])\n",
    "            predict[c].append(sent_predict[d])\n",
    "            flag=False\n",
    "    if flag:\n",
    "        answer[7].append(sent_ans[d])\n",
    "        predict[7].append(sent_predict[d])            \n",
    "            \n",
    "for c in range(len(category)):\n",
    "    print(category[c], len(answer[c]))\n",
    "    print('sentiment f1 score(micro):', f1_score(answer[c], predict[c], average='micro'))\n",
    "    print('sentiment f1 score(macro):', f1_score(answer[c], predict[c], average='macro'))\n",
    "    print(classification_report(answer[c], predict[c]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment accuracy: 0.7032348804500703\n",
      "sentiment f1 score(macro): 0.6452078116106083\n",
      "sentiment f1 score(micro): 0.7032348804500703\n",
      "sentiment f1 score(weight): 0.6984181962127978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          中立       0.77      0.83      0.80       788\n",
      "          正向       0.63      0.56      0.59       441\n",
      "          負向       0.57      0.53      0.55       193\n",
      "\n",
      "    accuracy                           0.70      1422\n",
      "   macro avg       0.66      0.64      0.65      1422\n",
      "weighted avg       0.70      0.70      0.70      1422\n",
      "\n",
      "功能\n",
      "sentiment f1 score(micro): 0.7045908183632734\n",
      "sentiment f1 score(macro): 0.6536575347536633\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          中立       0.83      0.76      0.79       293\n",
      "          正向       0.57      0.65      0.61       147\n",
      "          負向       0.54      0.59      0.56        61\n",
      "\n",
      "    accuracy                           0.70       501\n",
      "   macro avg       0.65      0.66      0.65       501\n",
      "weighted avg       0.72      0.70      0.71       501\n",
      "\n",
      "品質\n",
      "sentiment f1 score(micro): 0.6925925925925925\n",
      "sentiment f1 score(macro): 0.6424594529169693\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          中立       0.81      0.76      0.78       157\n",
      "          正向       0.56      0.59      0.58        74\n",
      "          負向       0.55      0.59      0.57        39\n",
      "\n",
      "    accuracy                           0.69       270\n",
      "   macro avg       0.64      0.65      0.64       270\n",
      "weighted avg       0.70      0.69      0.70       270\n",
      "\n",
      "配件\n",
      "sentiment f1 score(micro): 0.7246376811594203\n",
      "sentiment f1 score(macro): 0.6421955161993113\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          中立       0.88      0.77      0.82        48\n",
      "          正向       0.47      0.57      0.52        14\n",
      "          負向       0.50      0.71      0.59         7\n",
      "\n",
      "    accuracy                           0.72        69\n",
      "   macro avg       0.62      0.69      0.64        69\n",
      "weighted avg       0.76      0.72      0.74        69\n",
      "\n",
      "售後\n",
      "sentiment f1 score(micro): 0.5185185185185185\n",
      "sentiment f1 score(macro): 0.46991001829711504\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          中立       0.71      0.59      0.65        34\n",
      "          正向       0.28      0.33      0.30        15\n",
      "          負向       0.38      0.60      0.46         5\n",
      "\n",
      "    accuracy                           0.52        54\n",
      "   macro avg       0.46      0.51      0.47        54\n",
      "weighted avg       0.56      0.52      0.53        54\n",
      "\n",
      "外觀\n",
      "sentiment f1 score(micro): 0.8000000000000002\n",
      "sentiment f1 score(macro): 0.8362573099415206\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          中立       0.73      1.00      0.84        16\n",
      "          正向       1.00      0.50      0.67        12\n",
      "          負向       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.80        30\n",
      "   macro avg       0.91      0.83      0.84        30\n",
      "weighted avg       0.85      0.80      0.78        30\n",
      "\n",
      "價位\n",
      "sentiment f1 score(micro): 0.75\n",
      "sentiment f1 score(macro): 0.677807486631016\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          中立       0.88      0.80      0.84        46\n",
      "          正向       0.55      0.79      0.65        14\n",
      "          負向       0.60      0.50      0.55        12\n",
      "\n",
      "    accuracy                           0.75        72\n",
      "   macro avg       0.68      0.70      0.68        72\n",
      "weighted avg       0.77      0.75      0.75        72\n",
      "\n",
      "音量\n",
      "sentiment f1 score(micro): 0.5555555555555556\n",
      "sentiment f1 score(macro): 0.47703081232493\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          中立       0.83      0.45      0.59        22\n",
      "          正向       0.60      0.69      0.64        13\n",
      "          負向       0.11      1.00      0.20         1\n",
      "\n",
      "    accuracy                           0.56        36\n",
      "   macro avg       0.51      0.72      0.48        36\n",
      "weighted avg       0.73      0.56      0.60        36\n",
      "\n",
      "無\n",
      "sentiment f1 score(micro): 0.7282051282051283\n",
      "sentiment f1 score(macro): 0.6586090494548905\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          中立       0.84      0.81      0.82      1888\n",
      "          正向       0.57      0.66      0.61       824\n",
      "          負向       0.58      0.51      0.54       408\n",
      "\n",
      "    accuracy                           0.73      3120\n",
      "   macro avg       0.66      0.66      0.66      3120\n",
      "weighted avg       0.74      0.73      0.73      3120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Binary\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report, precision_recall_fscore_support\n",
    "sentiments = ['正向', '負向', '中立']\n",
    "sent_predict = []\n",
    "sent_ans = []\n",
    "    \n",
    "print('sentiment f1 score(macro):', f1_score(sent_ans, sent_predict, average='macro'))\n",
    "print('sentiment f1 score(micro):', f1_score(sent_ans, sent_predict, average='micro'))\n",
    "print('sentiment f1 score(weight):', f1_score(sent_ans, sent_predict, average='weighted'))\n",
    "print(classification_report(sent_ans, sent_predict))\n",
    "\n",
    "predict, answer = [], []\n",
    "for i in range(8):\n",
    "    predict.append([])\n",
    "    answer.append([])\n",
    "for c in range(len(category)):\n",
    "    for d in range(len(sent_predict)):\n",
    "        if category[c] in BERT_test[d]['target']:\n",
    "            answer[c].append(sent_ans[d])\n",
    "            predict[c].append(sent_predict[d])\n",
    "        flag=True\n",
    "        for cc in category:\n",
    "            if cc in  BERT_test[d]['target']:\n",
    "                flag=False\n",
    "        if flag:\n",
    "            answer[7].append(sent_predict[d])\n",
    "            predict[7].append(sent_ans[d])\n",
    "            \n",
    "for c in range(len(category)):\n",
    "    print(category[c])\n",
    "    print('sentiment f1 score(micro):', f1_score(answer[c], predict[c], average='micro'))\n",
    "    print('sentiment f1 score(macro):', f1_score(answer[c], predict[c], average='macro'))\n",
    "    print(classification_report(answer[c], predict[c]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 讀取之前訓練好的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此部分是屬於第二部分(transfer learning)的evaluate\n",
    "\n",
    "我有將每個模型跑出的五次實驗數據存下來 放在 predict_result中\n",
    "\n",
    "所以這部分可以直接跑evaluate 不用再跑模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#這邊看你要用的預測結果是剛剛跑出來的 還是之前已經存好的\n",
    "\n",
    "#之前存好的\n",
    "predicts = np.load('./predict_result/baseline_single.npy')\n",
    "#剛剛跑出來的\n",
    "# predicts = pred_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro\n",
      "0.6863360066977348\n",
      "micro\n",
      "0.7364275668073136\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report, precision_recall_fscore_support\n",
    "mamicro = []\n",
    "micros = []\n",
    "micro_dict = {_:[] for _ in category}\n",
    "for i in range(5):\n",
    "    micro = []\n",
    "    preds, anss = [], []\n",
    "    for j in category:\n",
    "        pred, ans = [], []\n",
    "        for k in range(1422):\n",
    "            if BERT_test[k]['target'].split('-')[1]==j:\n",
    "                pred.append(predicts[i*1422+k])\n",
    "                ans.append(BERT_test[k]['sentiment'])\n",
    "#         print('sentiment f1 score(macro):', f1_score(ans, pred, average='macro'))\n",
    "#         print('sentiment f1 score(micro):', f1_score(ans, pred, average='micro'))\n",
    "        preds+=pred\n",
    "        anss+=ans\n",
    "        micro.append(f1_score(ans, pred, average='micro'))\n",
    "        micro_dict[j].append(f1_score(ans, pred, average='micro'))\n",
    "    mamicro.append(np.mean(micro))\n",
    "    micros.append(f1_score(anss, preds, average='micro'))\n",
    "print('macro')\n",
    "print(np.mean(mamicro))\n",
    "print('micro')\n",
    "print(np.mean(micros))\n",
    "\n",
    "print('每個aspect category 在每次實驗中的sentiment f1:')\n",
    "for i in micro_dict.keys():\n",
    "    print(i)\n",
    "    for j in micro_dict[i]:\n",
    "        print(j)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
