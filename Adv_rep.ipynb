{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#require: pandas, tensorflow_hub, tensorflow_text, tensorflow_addons, sklearn\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras\n",
    "import tensorflow_text as text  # Imports TF ops for preprocessing.\n",
    "import model.tokenization as tokenization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping,CSVLogger\n",
    "from tensorflow.keras.layers import Input, Dense,Dropout,Embedding,LSTM,Bidirectional, Masking, TimeDistributed, Conv1D, MaxPooling1D, Flatten, concatenate, GRU\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "BERT_src = 'https://tfhub.dev/tensorflow/bert_zh_L-12_H-768_A-12/3'#'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/4' \n",
    "BERT_LAYER = hub.KerasLayer(BERT_src, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = ['功能', '品質', '無', '配件', '售後', '外觀', '價位', '音量']\n",
    "cate2idx = {cate:idx for idx, cate in enumerate(category)}\n",
    "idx2cate = {idx: cate for cate, idx in cate2idx.items()}\n",
    "sentiment = ['負向', '正向', '中立']\n",
    "sent2idx = {sent:idx for idx, sent in enumerate(sentiment)}\n",
    "idx2sent = {idx: sent for sent, idx in sent2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical devices cannot be modified after being initialized\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(gpus)!=0:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPUs visible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twoSentence2BERT(inputs, target_, onlytarget=False): #input as list of dictionary\n",
    "#     BERT_LAYER = hub.KerasLayer(BERT_src, trainable=False)\n",
    "    VOCAB_FILE = BERT_LAYER.resolved_object.vocab_file.asset_path.numpy()\n",
    "    tokenizer = tokenization.FullTokenizer(VOCAB_FILE, True) \n",
    "    output={'input_word_ids':[], 'input_mask':[], 'input_type_ids':[]}\n",
    "    for data in inputs:\n",
    "        count = 0\n",
    "        #tokenize origin sentence\n",
    "        tempword, tempmask, temptype=[], [], []\n",
    "        #add cls\n",
    "        tempword.append(tokenizer.convert_tokens_to_ids(['[CLS]'])[0])\n",
    "        tempmask.append(1)\n",
    "        temptype.append(0)\n",
    "        if not onlytarget:\n",
    "            sentence = data['sentence'] #string\n",
    "            tokenize_sentence = tokenizer.tokenize(sentence)\n",
    "            for ts in tokenize_sentence:\n",
    "                try:\n",
    "                    token_id = tokenizer.convert_tokens_to_ids([ts.lower()])\n",
    "                except:\n",
    "                    token_id = tokenizer.convert_tokens_to_ids(['[UNK]'])\n",
    "                tempword.append(token_id[0])\n",
    "                tempmask.append(1)\n",
    "                temptype.append(0)\n",
    "                count+=1\n",
    "            #add sep\n",
    "            if target_:\n",
    "                tempword.append(tokenizer.convert_tokens_to_ids(['[SEP]'])[0])\n",
    "                tempmask.append(1)\n",
    "                temptype.append(0)\n",
    "        if target_:\n",
    "            target = data['target'] #string        \n",
    "            tokenize_target = tokenizer.tokenize(target)        \n",
    "            for tt in tokenize_target:\n",
    "                try:\n",
    "                    token_id = tokenizer.convert_tokens_to_ids([tt.lower()])\n",
    "                except:\n",
    "                    token_id = tokenizer.convert_tokens_to_ids(['[UNK]'])\n",
    "                tempword.append(token_id[0])\n",
    "                tempmask.append(1)\n",
    "                temptype.append(1)\n",
    "                count+=1\n",
    "                if count>=128:\n",
    "                    break\n",
    "        if len(tempword)>127:\n",
    "            tempword=tempword[:127]\n",
    "            tempmask=tempmask[:127]\n",
    "            temptype=temptype[:127]  \n",
    "        #add sep\n",
    "        tempword.append(tokenizer.convert_tokens_to_ids(['[SEP]'])[0])\n",
    "        tempmask.append(1)\n",
    "        temptype.append(1)                \n",
    "        while(len(tempword)<128):\n",
    "            tempword.append(0)\n",
    "            tempmask.append(0)\n",
    "            temptype.append(0)            \n",
    "        output['input_word_ids'].append(tempword)\n",
    "        output['input_mask'].append(tempmask)\n",
    "        output['input_type_ids'].append(temptype)        \n",
    "    return output\n",
    "\n",
    "def BERTdata2Traindata(data, target=True, to_cate=True, objective = ['sentiment', 'aspect_category']):\n",
    "    from tensorflow.keras.utils import to_categorical\n",
    "    outputx = twoSentence2BERT(data, target)\n",
    "    outputy_sentiment = []\n",
    "    outputy_category = []\n",
    "    category=True\n",
    "    if 'aspect_category' not in objective:\n",
    "        category=False\n",
    "        \n",
    "    if to_cate:\n",
    "        for d in data:\n",
    "            if 'sentiment' in objective:\n",
    "                outputy_sentiment.append(sent2idx[d['sentiment']])\n",
    "            elif 'aspect_category' in objective:\n",
    "                outputy_category.append(cate2idx[d['aspect_category']])\n",
    "    else:\n",
    "        for d in data:\n",
    "            if 'sentiment' in objective:\n",
    "                outputy_sentiment.append(d['sentiment'])\n",
    "            elif 'aspect_category' in objective:\n",
    "                outputy_category.append(d['aspect_category'])\n",
    "        \n",
    "    if category:\n",
    "        if to_cate:\n",
    "            return outputx, to_categorical(outputy_sentiment, num_classes=len(sent2idx)), to_categorical(outputy_category, num_classes=len(cate2idx))\n",
    "        else:\n",
    "            return outputx, outputy_sentiment, outputy_category\n",
    "            \n",
    "    else:\n",
    "        if to_cate:\n",
    "            return outputx, to_categorical(outputy_sentiment, num_classes=len(sent2idx))\n",
    "        else:\n",
    "            return outputx, outputy_sentiment\n",
    "def transBERTtype(data, toBERT=True):\n",
    "    if toBERT: #input 每個資料都有三個key，每個key的維度都是128\n",
    "        return {k:np.array([data[i][k] for i in range(len(data))]) for k in data[0].keys()}\n",
    "    else: #原本BERT的形式\n",
    "        return [{k:data[k][i] for k in data.keys()} for i in range(len(data['input_word_ids']))]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #0:負向；1:正向；2:中立\n",
    "singer_chenyu_train = pd.read_csv('./data/chenyu_ABSA/dev.tsv', sep='\\t', header=0) #1238\n",
    "singer_chenyu_train.columns = ['sentiment', 'target', 'sentence']\n",
    "singer_chenyu_train = list(singer_chenyu_train.T.to_dict().values())\n",
    "for dta in range(len(singer_chenyu_train)):\n",
    "    singer_chenyu_train[dta]['sentiment']=idx2sent[singer_chenyu_train[dta]['sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:1663, test:1725\n",
      "restuarant:1908, laptop:1220, singer:6326\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "BERT_train, BERT_test = [], []\n",
    "restaurant, laptop, singer = [], [], []\n",
    "with open('./data/homeapp/PB-ACSent_BERT_train_0414.json', 'r', encoding='utf8') as file:\n",
    "    data = file.readlines()\n",
    "for d in data:\n",
    "    BERT_train.append(json.loads(d))\n",
    "    \n",
    "with open('./data/homeapp/PB-ACSent_BERT_test_0414.json', 'r', encoding='utf8') as file:\n",
    "    data = file.readlines()\n",
    "for d in data:\n",
    "    BERT_test.append(json.loads(d))\n",
    "\n",
    "with open('./data/translate/filt_restaurant.json', 'r', encoding='utf8') as file:\n",
    "    data = file.readlines()\n",
    "for d in data:\n",
    "    restaurant.append(json.loads(d))    \n",
    "    \n",
    "with open('./data/translate/filt_laptop.json', 'r', encoding='utf8') as file:\n",
    "    data = file.readlines()\n",
    "for d in data:\n",
    "    laptop.append(json.loads(d))    \n",
    "    \n",
    "with open('./data/Singer/SingerABSA.json', 'r', encoding='utf8') as file:\n",
    "    data = file.readlines()\n",
    "for d in data:\n",
    "    singer.append(json.loads(d))    \n",
    "    \n",
    "print('train:{}, test:{}'.format(len(BERT_train), len(BERT_test)))\n",
    "print('restuarant:{}, laptop:{}, singer:{}'.format(len(restaurant), len(laptop), len(singer)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source\n",
    "restaurant_x, restaurant_sentiment = BERTdata2Traindata(restaurant, to_cate=True, objective=['sentiment'])\n",
    "laptop_x, laptop_sentiment = BERTdata2Traindata(laptop, to_cate=True, objective=['sentiment'])\n",
    "singer_chenyu_x, singer_chenyu_sentiment = BERTdata2Traindata(singer_chenyu_train, to_cate=True, objective=['sentiment'])\n",
    "singer_x, singer_sentiment = BERTdata2Traindata(singer, to_cate=True, objective=['sentiment'])\n",
    "#target\n",
    "# train_x, train_sentiment, train_category = BERTdata2Traindata(BERT_train)\n",
    "# test_x, test_sentiment, test_category = BERTdata2Traindata(BERT_test)\n",
    "train_x, train_sentiment = BERTdata2Traindata(BERT_train, to_cate=True, objective=['sentiment'])\n",
    "test_x, test_sentiment = BERTdata2Traindata(BERT_test, to_cate=True, objective=['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Reverse Layer\n",
    "@tf.custom_gradient\n",
    "def grad_reverse(x):\n",
    "    y = tf.identity(x)\n",
    "    def custom_grad(dy):\n",
    "        return -dy\n",
    "    return y, custom_grad\n",
    "\n",
    "class GradReverse(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, x):\n",
    "        return grad_reverse(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence base, multi-task approach\n",
    "def create_classify_model(data_size, batch_size = 16, epochs=10):\n",
    "    import model.optimization as optimization\n",
    "    input1 = Input(shape=(128,), name='input_word_ids', dtype=tf.int32)\n",
    "    input2 = Input(shape=(128,),name='input_mask', dtype=tf.int32)\n",
    "    input3 = Input(shape=(128,),name='input_type_ids', dtype=tf.int32)\n",
    "    bert_layer = hub.KerasLayer(BERT_src, trainable=True, output_key='pooled_output', name='bert_layer')\n",
    "    output = bert_layer({'input_word_ids':input1, 'input_mask':input2, 'input_type_ids':input3})\n",
    "#     output = Dense(128, name = 'presentation_')(output)\n",
    "    \n",
    "    sentiment_output = Dense(64, activation='relu', name = 'sentiment_pre', \n",
    "                             kernel_initializer=keras.initializers.glorot_normal(0), bias_initializer='zeros')(output)\n",
    "#     sentiment_output = Dropout(0.2, name='sentiment_drop')(sentiment_output)\n",
    "    sentiment_output = Dense(3, activation='softmax', name = 'sentiment', \n",
    "                             kernel_initializer=keras.initializers.glorot_normal(0), bias_initializer='zeros')(sentiment_output) #softmax會讓所有的output總和=1\n",
    "\n",
    "    category_output = Dense(128, activation='relu', name = 'category_pre', \n",
    "                             kernel_initializer=keras.initializers.glorot_normal(0), bias_initializer='zeros')(output)    \n",
    "#     category_output = Dropout(0.2, name='category_drop')(category_output)\n",
    "    category_output = Dense(8, activation='softmax', name = 'category', \n",
    "                             kernel_initializer=keras.initializers.glorot_normal(0), bias_initializer='zeros')(category_output) #softmax會讓所有的output總和=1\n",
    "    \n",
    "    output_model = Model(inputs = [input1, input2, input3], outputs = [sentiment_output, category_output])\n",
    "    optimizer = optimization.create_optimizer(\n",
    "    5e-5, (data_size//batch_size)*epochs, int((epochs*data_size*0.1)//batch_size), 0.0, 'lamb')\n",
    "    \n",
    "    output_model.compile(optimizer=optimizer, \n",
    "                         loss={'sentiment':'categorical_crossentropy', 'category':'categorical_crossentropy'},\n",
    "                         loss_weights={'sentiment':1., 'category':1})\n",
    "    return output_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence base, only sentence approach\n",
    "def create_temp_model(data_size, batch_size = 16, epochs=10, domain_size = 1):\n",
    "    import model.optimization as optimization\n",
    "    input1 = Input(shape=(128,), name='input_word_ids', dtype=tf.int32)\n",
    "    input2 = Input(shape=(128,),name='input_mask', dtype=tf.int32)\n",
    "    input3 = Input(shape=(128,),name='input_type_ids', dtype=tf.int32)\n",
    "    bert_layer = hub.KerasLayer(BERT_src, trainable=True, output_key='pooled_output', name='bert_layer')\n",
    "    output = bert_layer({'input_word_ids':input1, 'input_mask':input2, 'input_type_ids':input3})\n",
    "#     output = Dense(128, name = 'presentation_')(output)\n",
    "    \n",
    "    sentiment_output = Dense(64, activation='relu', name = 'sentiment_pre', \n",
    "                             kernel_initializer=keras.initializers.he_normal(0), bias_initializer='zeros')(output)\n",
    "#     sentiment_output = Dropout(0.2, name='sentiment_drop')(sentiment_output)\n",
    "    sentiment_output = Dense(3, activation='softmax', name = 'sentiment', \n",
    "                             kernel_initializer=keras.initializers.he_normal(0), bias_initializer='zeros')(sentiment_output) #softmax會讓所有的output總和=1\n",
    "    if domain_size>1:\n",
    "        temp_output = GradReverse()(output)\n",
    "        dis_output = Dense(64, activation='relu', name = 'dis_pre', \n",
    "                             kernel_initializer=keras.initializers.he_normal(0), bias_initializer='zeros')(temp_output)\n",
    "        dis_output = Dense(domain_size, activation='softmax', name = 'discriminator', \n",
    "                             kernel_initializer=keras.initializers.he_normal(0), bias_initializer='zeros')(dis_output) #softmax會讓所有的output總和=1\n",
    "\n",
    "    optimizer = optimization.create_optimizer(\n",
    "    5e-5, (data_size//batch_size)*epochs, int((epochs*data_size*0.1)//batch_size), 0.0, 'adamw')\n",
    "    if domain_size>1:        \n",
    "#         decoding_model = Model(inputs = [input1, input2, input3], outputs = sentiment_output)\n",
    "#         decoding_model.compile(optimizer=optimizer, loss=categorical_crossentropy)\n",
    "#         discriminator_model = Model(inputs = [input1, input2, input3], outputs = dis_output)\n",
    "#         discriminator_model.compile(optimizer=optimizer, loss=categorical_crossentropy)        \n",
    "        output_model = Model(inputs = [input1, input2, input3], outputs = [sentiment_output, dis_output])\n",
    "        final_model = Model(inputs = [input1, input2, input3], outputs = sentiment_output) \n",
    "        output_model.compile(optimizer=optimizer, \n",
    "                             loss={'sentiment':'categorical_crossentropy', 'discriminator':'categorical_crossentropy'},\n",
    "                            loss_weights={'sentiment':1., 'discriminator':.3})\n",
    "    else:\n",
    "        output_model = Model(inputs = [input1, input2, input3], outputs = sentiment_output)\n",
    "        final_model = Model(inputs = [input1, input2, input3], outputs = sentiment_output) \n",
    "        output_model.compile(optimizer=optimizer, \n",
    "                             loss={'sentiment':'categorical_crossentropy'})\n",
    "        \n",
    "    return output_model, final_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## no BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import Counter\n",
    "import preprocessing as preprocess\n",
    "idx2word, word2idx,char_embeddings = preprocess.get_pretrain_char_emb('CKIP')\n",
    "special_words = ['<PAD>', '<UNK>'] # 特殊词表示\n",
    "with open('/tf/notebooks/code/old/zh-nlp-demo/data/char_vocabs.txt', \"r\", encoding=\"utf8\") as fo:\n",
    "    char_vocabs = [line.strip() for line in fo]\n",
    "# char_vocabs = []\n",
    "# for i in range(0x4e00,0x9fa6):\n",
    "#     char_vocabs.append(chr(i))\n",
    "char_vocabs = special_words + char_vocabs\n",
    "char_vocabs = list(idx2word.values())\n",
    "char_vocabs.sort()\n",
    "\n",
    "def create_nobert_model(tags = 8, embed_size = 50, pretrain_emb=True): #compile first\n",
    "    inputs = Input(shape=(128,), name='encoding_input')\n",
    "    output = Masking(mask_value=word2idx['<PAD>'], name='encoding_mask')(inputs)\n",
    "    \n",
    "    tgt_inputs = Input(shape=(10,), name='target_input')\n",
    "    tgt_output = Masking(mask_value=word2idx['<PAD>'], name='tgt_mask')(tgt_inputs)\n",
    "    \n",
    "    encoding = concatenate([output, tgt_output], axis=1)\n",
    "    \n",
    "    if pretrain_emb:\n",
    "        embed_size = len(char_embeddings['我'])\n",
    "        embedding_matrix = np.zeros((len(word2idx), embed_size))\n",
    "        for word, i in word2idx.items():\n",
    "            embedding_vector = char_embeddings.get(word)\n",
    "            if embedding_vector is not None:\n",
    "                # words not found in embedding index will be all-zeros.\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "        encoding = Embedding(len(char_vocabs), embed_size, weights=[embedding_matrix], trainable=True, name='encoding_emb')(encoding)  \n",
    "    else:\n",
    "        encoding = Embedding(len(char_vocabs), embed_size, trainable=True, name='encoding_emb')(encoding)\n",
    "#         output = Embedding(len(char_vocabs), embed_size, trainable=True, name='encoding_emb')(output)  \n",
    "#         tgt_output = Embedding(len(char_vocabs), embed_size, trainable=True, name='tgt_emb')(tgt_output)  \n",
    "    \n",
    "#    decoding_output = Dense(tags, activation='softmax', name='output')(encoding)\n",
    "\n",
    "    cnn = Conv1D(1, kernel_size=1, strides=1,activation='relu', name='dis_conv')(encoding)\n",
    "    cnn = MaxPooling1D(10, name='dis_maxpooling1d')(cnn)\n",
    "    flat = Flatten(name='dis_flatten')(cnn)\n",
    "    \n",
    "    decoding_output = Dense(tags, activation='sigmoid', name='output')(flat)\n",
    "    \n",
    "    model = Model([inputs, tgt_inputs], decoding_output)\n",
    "    model.compile(optimizer=\"adam\",loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_nobert_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:1001, test:1075\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "#PB-Sent_BERT_same_aux_NLI-B_train06-16.json\n",
    "type_ = []\n",
    "BERT_train, BERT_test = [], []\n",
    "with open('../homeapp/LabelAPP/PB-AC_BERT_same_aux_NLI-M_train06-16.json', 'r', encoding='utf8') as file:\n",
    "    data = file.readlines()\n",
    "for d in data:\n",
    "    BERT_train.append(json.loads(d))\n",
    "    \n",
    "with open('../homeapp/LabelAPP/PB-AC_BERT_same_aux_NLI-M_test06-16.json', 'r', encoding='utf8') as file:\n",
    "    data = file.readlines()\n",
    "for d in data:\n",
    "    BERT_test.append(json.loads(d))\n",
    "\n",
    "print('train:{}, test:{}'.format(len(BERT_train), len(BERT_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans(data, maxlen=128):\n",
    "    x = [np.array([word2idx.get(row, word2idx['<UNK>']) for row in s]) for s in data]\n",
    "    x = np.array(pad_sequences(x, maxlen=maxlen, value=word2idx['<PAD>'], padding='post', truncating=\"post\"))\n",
    "    return x\n",
    "sentidx ={'中立':0, \n",
    "          '正向':1, \n",
    "          '負向':2}\n",
    "cateidx = {category[i]:i for i in range(len(category))}\n",
    "sentence = {'train':trans([i['sentence'] for i in BERT_train]),\n",
    "           'test':trans([i['sentence'] for i in BERT_test])}\n",
    "target = {'train':trans([i['target'] for i in BERT_train], 10),\n",
    "           'test':trans([i['target'] for i in BERT_test], 10)}\n",
    "cate = {'train':  [[1 if category[j] in i['aspect_category'] else 0 for j in range(8)] for i in BERT_train],\n",
    "    'test':  [[1 if category[j] in i['aspect_category'] else 0 for j in range(8)] for i in BERT_test]    }\n",
    "# sentiment = {'train':  to_categorical([sentidx[i['sentiment']] for i in BERT_train]),\n",
    "#              'test':  to_categorical([sentidx[i['sentiment']] for i in BERT_test])    \n",
    "#             }\n",
    "# sentiment = {'train':  np.array([sentidx[i['sentiment']] for i in BERT_train]),\n",
    "#              'test':  np.array([sentidx[i['sentiment']] for i in BERT_test])    \n",
    "#             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "63/63 [==============================] - 2s 27ms/step - loss: 0.6662 - accuracy: 0.1849\n",
      "Epoch 2/7\n",
      "63/63 [==============================] - 2s 26ms/step - loss: 0.5236 - accuracy: 0.2487\n",
      "Epoch 3/7\n",
      "63/63 [==============================] - 2s 25ms/step - loss: 0.4289 - accuracy: 0.2604\n",
      "Epoch 4/7\n",
      "63/63 [==============================] - 2s 25ms/step - loss: 0.3984 - accuracy: 0.3296\n",
      "Epoch 5/7\n",
      "63/63 [==============================] - 2s 24ms/step - loss: 0.3886 - accuracy: 0.3602\n",
      "Epoch 6/7\n",
      "63/63 [==============================] - 2s 25ms/step - loss: 0.3728 - accuracy: 0.4343\n",
      "Epoch 7/7\n",
      "63/63 [==============================] - 2s 25ms/step - loss: 0.3667 - accuracy: 0.4266\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1422, 1075]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-185-718e49486d32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentiment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 320\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1422, 1075]"
     ]
    }
   ],
   "source": [
    "history = model.fit(x={'encoding_input':sentence['train'], 'target_input':target['train']}, \n",
    "                    y=np.array(cate['train']), batch_size=16, epochs=7, verbose=1)\n",
    "pred = model.predict([sentence['test'], target['test']])\n",
    "# pred = [np.argmax(i) for i in pred]\n",
    "# ans = [np.argmax(i) for i in sentiment['test']]\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "print(accuracy_score(ans, pred))\n",
    "print(classification_report(ans, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 其他設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def sample_data(data_list, datasize, random_=True):\n",
    "    #data_list = [BERT_x, sentiment, (category)]\n",
    "    if random_:\n",
    "        samples = random.sample(range(len(data_list[1])), datasize)\n",
    "    else:\n",
    "        samples = list(range(datasize))        \n",
    "    bert_x = data_list[0]\n",
    "    bert_x = {k:np.array([bert_x[k][i] for i in samples]) for k in bert_x.keys()}\n",
    "    sentiment = np.array(data_list[1])\n",
    "    sentiment = np.array([sentiment[i] for i in samples])\n",
    "    if len(data_list)>2:\n",
    "        category = np.array(data_list[2])\n",
    "        category = np.array([category[i] for i in samples])\n",
    "        return bert_x, sentiment, category\n",
    "    else:\n",
    "        return bert_x, sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_get_weight(model, keyword='', not_=False):\n",
    "    origin_weight = []\n",
    "    for layer in model.layers:\n",
    "        if not_:\n",
    "            if not layer.name.startswith(keyword): \n",
    "                origin_weight.append(np.array(layer.get_weights()))\n",
    "        else:\n",
    "            if layer.name.startswith(keyword): \n",
    "                origin_weight.append(np.array(layer.get_weights()))\n",
    "    return np.array(origin_weight)\n",
    "\n",
    "def update_weights(model, update_weight, keyword='', not_=False):\n",
    "    k=0\n",
    "    for layer in model.layers:\n",
    "        if not_:\n",
    "            if not layer.name.startswith(keyword):\n",
    "                layer.set_weights(update_weight[k])\n",
    "                k+=1\n",
    "        else:\n",
    "            if layer.name.startswith(keyword):\n",
    "                layer.set_weights(update_weight[k])\n",
    "                k+=1\n",
    "def update_weights_forsame(model, model_src):\n",
    "    for layer in model.layers:\n",
    "        flag = False\n",
    "        for layer_src in model_src.layers:\n",
    "            if layer.name==layer_src.name and len(layer.get_weights())==len(layer_src.get_weights()) and flag==False:\n",
    "                try: \n",
    "                    layer.set_weights(layer_src.get_weights())\n",
    "                    flag = True\n",
    "                except:\n",
    "                    print('error!')\n",
    "        if flag==False:\n",
    "            print('model layer: \"', layer.name, '\" not in source model')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Reptile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_x = [singer_x, restaurant_x, laptop_x]\n",
    "src_y = [singer_sentiment, restaurant_sentiment, laptop_sentiment]\n",
    "dev_x, dev_y = sample_data([singer_chenyu_x, singer_chenyu_sentiment], 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itr = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.43-------------\n",
      "new [-0.3423988  -0.09649575 -0.13309965] origin [-0.34104967 -0.09674136 -0.1330885 ] lr 1.0\n",
      "total spend 89 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.57-------------\n",
      "new [-0.3425071  -0.09662279 -0.13293625] origin [-0.3423988  -0.09649575 -0.13309965] lr 0.98\n",
      "total spend 156 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.5333333333333333-------------\n",
      "new [-0.3425091  -0.09665092 -0.13291007] origin [-0.3425071  -0.09662279 -0.13293625] lr 0.96\n",
      "total spend 224 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.5666666666666667-------------\n",
      "new [-0.34250748 -0.0966581  -0.13290375] origin [-0.3425091  -0.09665092 -0.13291007] lr 0.94\n",
      "total spend 295 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.5933333333333334-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.0966581  -0.13290375] lr 0.92\n",
      "total spend 365 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.9\n",
      "total spend 436 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.88\n",
      "total spend 507 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.86\n",
      "total spend 579 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.84\n",
      "total spend 650 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.82\n",
      "total spend 721 seconds\n",
      "itr = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.8\n",
      "total spend 793 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.78\n",
      "total spend 864 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.76\n",
      "total spend 936 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.74\n",
      "total spend 1007 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.72\n",
      "total spend 1079 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.7\n",
      "total spend 1151 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.68\n",
      "total spend 1222 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.66\n",
      "total spend 1294 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.64\n",
      "total spend 1365 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.62\n",
      "total spend 1437 seconds\n",
      "itr = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.6\n",
      "total spend 1508 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.58\n",
      "total spend 1580 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.56\n",
      "total spend 1651 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.54\n",
      "total spend 1723 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.52\n",
      "total spend 1794 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.5\n",
      "total spend 1866 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.48\n",
      "total spend 1937 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.46\n",
      "total spend 2009 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.44\n",
      "total spend 2080 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.42\n",
      "total spend 2152 seconds\n",
      "itr = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.4\n",
      "total spend 2224 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.38\n",
      "total spend 2295 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.36\n",
      "total spend 2367 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.34\n",
      "total spend 2438 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.32\n",
      "total spend 2510 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.3\n",
      "total spend 2582 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.28\n",
      "total spend 2653 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.26\n",
      "total spend 2725 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.24\n",
      "total spend 2797 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.22\n",
      "total spend 2868 seconds\n",
      "itr = 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.2\n",
      "total spend 2940 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.18\n",
      "total spend 3011 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.16\n",
      "total spend 3083 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.14\n",
      "total spend 3155 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.12\n",
      "total spend 3226 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.1\n",
      "total spend 3298 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.08\n",
      "total spend 3370 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.06\n",
      "total spend 3441 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.04\n",
      "total spend 3513 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.6133333333333333-------------\n",
      "new [-0.34250748 -0.09665912 -0.13290295] origin [-0.34250748 -0.09665912 -0.13290295] lr 0.02\n",
      "total spend 3585 seconds\n",
      "total spend 3585 seconds\n"
     ]
    }
   ],
   "source": [
    "#這邊有一點比較遺憾的是，在reptile的實驗中，outer iteration通常都是設十萬以上\n",
    "try:\n",
    "    del tmp_model\n",
    "except:\n",
    "    ;\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "outer_iteration = 50 #一個iteration大概3.1秒(一個domain)\n",
    "inner_iteration = 3\n",
    "batch = 5\n",
    "epochs = inner_iteration\n",
    "datasize_per_task = 32\n",
    "meta_step_size = 1\n",
    "domain_adver = len(src_y)\n",
    "import time\n",
    "starttime = time.time()\n",
    "tmp_model, output_model = create_temp_model(data_size=len(singer_sentiment), epochs=epochs, batch_size=datasize_per_task, domain_size = domain_adver)\n",
    "for itr in range(outer_iteration):\n",
    "    if itr%10==0:\n",
    "        print('itr =',itr)\n",
    "    done_step = itr/outer_iteration\n",
    "    cur_meta_step_size = (1-done_step)*meta_step_size\n",
    "    origin_weights = model_get_weight(tmp_model)\n",
    "    new_weights = []\n",
    "    losses = []\n",
    "    advloss = []\n",
    "    adv_loss = 0\n",
    "    domain_num = 0\n",
    "    for x, y in zip(src_x, src_y):     \n",
    "        loss = []\n",
    "        for i in range(inner_iteration):\n",
    "            if domain_adver>1:\n",
    "                tmp_train_x, tmp_sentiment = sample_data([x, y], datasize_per_task*batch)  \n",
    "                domain_ans = to_categorical(len(tmp_sentiment)*[domain_num], num_classes=domain_adver)\n",
    "#                 total_loss = tmp_model.train_on_batch(x=tmp_train_x, y=[tmp_sentiment, domain_ans])                \n",
    "#                 loss = round(total_loss[1], 5) \n",
    "#                 adv_loss = round(total_loss[2], 5)\n",
    "                loss, adv_loss = 0.0, 0.0\n",
    "                tmp_model.fit(tmp_train_x,[tmp_sentiment, domain_ans],\n",
    "                            batch_size=datasize_per_task, epochs=inner_iteration, verbose=0) #一個batch會更新一次參數\n",
    "                #這邊因為模型裡面本來就有gradient reverse layer，所以可以直接訓練沒問題\n",
    "            else:\n",
    "                tmp_train_x, tmp_sentiment = sample_data([x, y], datasize_per_task)  \n",
    "                loss = tmp_model.train_on_batch(x=tmp_train_x, y=tmp_sentiment)\n",
    "                loss = round(loss, 5)\n",
    "\n",
    "        new_weights.append(model_get_weight(tmp_model))\n",
    "        update_weights(tmp_model, origin_weights)\n",
    "        losses.append(loss)\n",
    "        advloss.append(adv_loss) #只看最後一個的loss好了\n",
    "        domain_num+=1\n",
    "    #update weights\n",
    "    new_weights = np.array(new_weights)\n",
    "    new_weight = new_weights[0]\n",
    "    for i in range(len(new_weights)-1):\n",
    "        new_weight+=new_weights[i+1]\n",
    "    new_weight/=len(new_weights)    \n",
    "    new_weight = origin_weights + ((new_weight-origin_weights)*cur_meta_step_size)\n",
    "#     print('new', new_weight[3][0][0][0], 'origin',origin_weights[3][0][0][0], 'lr',round(cur_meta_step_size, 5))\n",
    "    if domain_adver>1:\n",
    "        pred = tmp_model.predict(dev_x)[0]\n",
    "    else:\n",
    "        pred = tmp_model.predict(dev_x)\n",
    "        \n",
    "    pred = [np.argmax(i) for i in pred]\n",
    "    ans = [np.argmax(i) for i in dev_y]\n",
    "    print('---------{}-------------'.format(accuracy_score(ans, pred)))\n",
    "    \n",
    "    print('new', new_weight[-1][0][0], 'origin',origin_weights[-1][0][0], 'lr',round(cur_meta_step_size, 5))\n",
    "#     print('lr', round(cur_meta_step_size, 5), '\\tloss', losses, '\\t adv loss', round(np.mean(advloss), 5), '\\t spend', int(time.time()-starttime))\n",
    "    print('total spend {} seconds'.format(int(time.time()-starttime)))\n",
    "    update_weights(tmp_model, new_weight)\n",
    "    del new_weight, origin_weights, new_weights\n",
    "print('total spend {} seconds'.format(int(time.time()-starttime)))\n",
    "# output_model.save('rep_adv_opt_lamb.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
