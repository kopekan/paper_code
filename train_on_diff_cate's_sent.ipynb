{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#require: pandas, tensorflow_hub, tensorflow_text, tensorflow_addons, sklearn\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras\n",
    "import tensorflow_text as text  # Imports TF ops for preprocessing.\n",
    "import model.tokenization as tokenization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping,CSVLogger\n",
    "from tensorflow.keras.layers import Input, Dense,Dropout,Embedding,LSTM,Bidirectional, Masking, TimeDistributed, Conv1D, MaxPooling1D, Flatten, concatenate, GRU\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "BERT_src = 'https://tfhub.dev/tensorflow/bert_zh_L-12_H-768_A-12/3'#'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/4' \n",
    "BERT_LAYER = hub.KerasLayer(BERT_src, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = ['功能', '品質', '無', '配件', '售後', '外觀', '價位', '音量']\n",
    "cate2idx = {cate:idx for idx, cate in enumerate(category)}\n",
    "idx2cate = {idx: cate for cate, idx in cate2idx.items()}\n",
    "sentiment = ['負向', '正向', '中立']\n",
    "sent2idx = {sent:idx for idx, sent in enumerate(sentiment)}\n",
    "idx2sent = {idx: sent for sent, idx in sent2idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twoSentence2BERT(inputs, target_, onlytarget=False): #input as list of dictionary\n",
    "#     BERT_LAYER = hub.KerasLayer(BERT_src, trainable=False)\n",
    "    VOCAB_FILE = BERT_LAYER.resolved_object.vocab_file.asset_path.numpy()\n",
    "    tokenizer = tokenization.FullTokenizer(VOCAB_FILE, True) \n",
    "    output={'input_word_ids':[], 'input_mask':[], 'input_type_ids':[]}\n",
    "    for data in inputs:\n",
    "        count = 0\n",
    "        #tokenize origin sentence\n",
    "        tempword, tempmask, temptype=[], [], []\n",
    "        #add cls\n",
    "        tempword.append(tokenizer.convert_tokens_to_ids(['[CLS]'])[0])\n",
    "        tempmask.append(1)\n",
    "        temptype.append(0)\n",
    "        if not onlytarget:\n",
    "            sentence = data['sentence'] #string\n",
    "            tokenize_sentence = tokenizer.tokenize(sentence)\n",
    "            for ts in tokenize_sentence:\n",
    "                try:\n",
    "                    token_id = tokenizer.convert_tokens_to_ids([ts.lower()])\n",
    "                except:\n",
    "                    token_id = tokenizer.convert_tokens_to_ids(['[UNK]'])\n",
    "                tempword.append(token_id[0])\n",
    "                tempmask.append(1)\n",
    "                temptype.append(0)\n",
    "                count+=1\n",
    "            #add sep\n",
    "            if target_:\n",
    "                tempword.append(tokenizer.convert_tokens_to_ids(['[SEP]'])[0])\n",
    "                tempmask.append(1)\n",
    "                temptype.append(0)\n",
    "        if target_:\n",
    "            target = data['target'] #string        \n",
    "            tokenize_target = tokenizer.tokenize(target)        \n",
    "            for tt in tokenize_target:\n",
    "                try:\n",
    "                    token_id = tokenizer.convert_tokens_to_ids([tt.lower()])\n",
    "                except:\n",
    "                    token_id = tokenizer.convert_tokens_to_ids(['[UNK]'])\n",
    "                tempword.append(token_id[0])\n",
    "                tempmask.append(1)\n",
    "                temptype.append(1)\n",
    "                count+=1\n",
    "                if count>=128:\n",
    "                    break\n",
    "        if len(tempword)>127:\n",
    "            tempword=tempword[:127]\n",
    "            tempmask=tempmask[:127]\n",
    "            temptype=temptype[:127]  \n",
    "        #add sep\n",
    "        tempword.append(tokenizer.convert_tokens_to_ids(['[SEP]'])[0])\n",
    "        tempmask.append(1)\n",
    "        temptype.append(1)                \n",
    "        while(len(tempword)<128):\n",
    "            tempword.append(0)\n",
    "            tempmask.append(0)\n",
    "            temptype.append(0)            \n",
    "        output['input_word_ids'].append(tempword)\n",
    "        output['input_mask'].append(tempmask)\n",
    "        output['input_type_ids'].append(temptype)        \n",
    "    return output\n",
    "\n",
    "def BERTdata2Traindata(data, target=True, to_cate=True, objective = ['sentiment', 'aspect_category']):\n",
    "    from tensorflow.keras.utils import to_categorical\n",
    "    outputx = twoSentence2BERT(data, target)\n",
    "    outputy_sentiment = []\n",
    "    outputy_category = []\n",
    "    category=True\n",
    "    if 'aspect_category' not in objective:\n",
    "        category=False\n",
    "        \n",
    "    if to_cate:\n",
    "        for d in data:\n",
    "            if 'sentiment' in objective:\n",
    "                outputy_sentiment.append(sent2idx[d['sentiment']])\n",
    "            elif 'aspect_category' in objective:\n",
    "                outputy_category.append(cate2idx[d['aspect_category']])\n",
    "    else:\n",
    "        for d in data:\n",
    "            if 'sentiment' in objective:\n",
    "                outputy_sentiment.append(d['sentiment'])\n",
    "            elif 'aspect_category' in objective:\n",
    "                outputy_category.append(d['aspect_category'])\n",
    "        \n",
    "    if category:\n",
    "        if to_cate:\n",
    "            return outputx, to_categorical(outputy_sentiment, num_classes=len(sent2idx)), to_categorical(outputy_category, num_classes=len(cate2idx))\n",
    "        else:\n",
    "            return outputx, outputy_sentiment, outputy_category\n",
    "            \n",
    "    else:\n",
    "        if to_cate:\n",
    "            return outputx, to_categorical(outputy_sentiment, num_classes=len(sent2idx))\n",
    "        else:\n",
    "            return outputx, outputy_sentiment\n",
    "def transBERTtype(data, toBERT=True):\n",
    "    if toBERT: #input 每個資料都有三個key，每個key的維度都是128\n",
    "        return {k:np.array([data[i][k] for i in range(len(data))]) for k in data[0].keys()}\n",
    "    else: #原本BERT的形式\n",
    "        return [{k:data[k][i] for k in data.keys()} for i in range(len(data['input_word_ids']))]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = [], []\n",
    "import json\n",
    "for c in category:\n",
    "    BERT_train = []\n",
    "    dir_ = './data/homeapp/diff_cate/'+c+'/train.json'\n",
    "    with open(dir_, 'r', encoding='utf8') as file:\n",
    "        data = file.readlines()\n",
    "    for d in data:\n",
    "        BERT_train.append(json.loads(d))\n",
    "    train.append(BERT_train)\n",
    "    \n",
    "    BERT_test = []\n",
    "    dir_ = './data/homeapp/diff_cate/'+c+'/test.json'\n",
    "    with open(dir_, 'r', encoding='utf8') as file:\n",
    "        data = file.readlines()\n",
    "    for d in data:\n",
    "        BERT_test.append(json.loads(d))\n",
    "    test.append(BERT_test)\n",
    "all_train, all_test = [], []\n",
    "for i in train:\n",
    "    all_train+=i\n",
    "for i in test:\n",
    "    all_test+=i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 資料統計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cate \t train \t test\n",
      "功能 \t 375 \t 422\n",
      "品質 \t 235 \t 204\n",
      "無 \t 411 \t 494\n",
      "配件 \t 106 \t 83\n",
      "售後 \t 73 \t 50\n",
      "外觀 \t 66 \t 69\n",
      "價位 \t 49 \t 63\n",
      "音量 \t 30 \t 37\n",
      "overall\t1345\t1422\n",
      "----------\n",
      "train\n",
      "cate\t正向\t負向\t中立\n",
      "功能\t0.18\t0.02\t0.81\t\n",
      "品質\t0.56\t0.39\t0.05\t\n",
      "無\t0.27\t0.12\t0.62\t\n",
      "配件\t0.31\t0.14\t0.55\t\n",
      "售後\t0.44\t0.3\t0.26\t\n",
      "外觀\t0.15\t0.08\t0.77\t\n",
      "價位\t0.31\t0.33\t0.37\t\n",
      "音量\t0.4\t0.6\t0.0\t\n",
      "test\n",
      "cate\t正向\t負向\t中立\n",
      "功能\t0.15\t0.03\t0.82\t\n",
      "品質\t0.59\t0.36\t0.04\t\n",
      "無\t0.3\t0.1\t0.6\t\n",
      "配件\t0.31\t0.1\t0.59\t\n",
      "售後\t0.34\t0.38\t0.28\t\n",
      "外觀\t0.26\t0.09\t0.65\t\n",
      "價位\t0.44\t0.16\t0.4\t\n",
      "音量\t0.51\t0.35\t0.14\t\n",
      "train+test\n",
      "cate\t正向\t負向\t中立\n",
      "功能\t0.16\t0.02\t0.81\t\n",
      "品質\t0.57\t0.38\t0.05\t\n",
      "無\t0.28\t0.11\t0.61\t\n",
      "配件\t0.31\t0.12\t0.57\t\n",
      "售後\t0.4\t0.33\t0.27\t\n",
      "外觀\t0.21\t0.08\t0.71\t\n",
      "價位\t0.38\t0.23\t0.38\t\n",
      "音量\t0.46\t0.46\t0.07\t\n",
      "total\t0.31\t0.15\t0.54\t\n"
     ]
    }
   ],
   "source": [
    "print('cate \\t train \\t test')\n",
    "for c in range(len(category)):\n",
    "    print(category[c],'\\t',len(train[c]),'\\t', len(test[c]))\n",
    "print('overall\\t{}\\t{}'.format(len(all_train), len(all_test)))\n",
    "print('----------')\n",
    "print('train')\n",
    "print('cate\\t正向\\t負向\\t中立')\n",
    "for c in range(len(category)):\n",
    "    po, ne, nu = 0, 0, 0\n",
    "    for i in train[c]:\n",
    "        if i['sentiment']=='正向':\n",
    "            po+=1\n",
    "        elif i['sentiment']=='負向':\n",
    "            ne+=1\n",
    "        else:\n",
    "            nu+=1\n",
    "    print('{}\\t{}\\t{}\\t{}\\t'.format(category[c], round(po/len(train[c]),2), round(ne/len(train[c]),2), round(nu/len(train[c]),2)))\n",
    "print('test')\n",
    "print('cate\\t正向\\t負向\\t中立')\n",
    "for c in range(len(category)):\n",
    "    po, ne, nu = 0, 0, 0\n",
    "    for i in test[c]:\n",
    "        if i['sentiment']=='正向':\n",
    "            po+=1\n",
    "        elif i['sentiment']=='負向':\n",
    "            ne+=1\n",
    "        else:\n",
    "            nu+=1\n",
    "    print('{}\\t{}\\t{}\\t{}\\t'.format(category[c], round(po/len(test[c]),2), round(ne/len(test[c]),2), round(nu/len(test[c]),2)))\n",
    "\n",
    "print('train+test')\n",
    "print('cate\\t正向\\t負向\\t中立')\n",
    "for c in range(len(category)):\n",
    "    po, ne, nu = 0, 0, 0\n",
    "    for i in test[c]:\n",
    "        if i['sentiment']=='正向':\n",
    "            po+=1\n",
    "        elif i['sentiment']=='負向':\n",
    "            ne+=1\n",
    "        else:\n",
    "            nu+=1\n",
    "    for i in train[c]:\n",
    "        if i['sentiment']=='正向':\n",
    "            po+=1\n",
    "        elif i['sentiment']=='負向':\n",
    "            ne+=1\n",
    "        else:\n",
    "            nu+=1\n",
    "    print('{}\\t{}\\t{}\\t{}\\t'.format(category[c], round(po/(len(test[c])+len(train[c])),2), round(ne/(len(test[c])+len(train[c])),2), round(nu/(len(test[c])+len(train[c])), 2)))\n",
    "po, ne, nu = 0, 0, 0\n",
    "for i in all_train:\n",
    "    if i['sentiment']=='正向':\n",
    "        po+=1\n",
    "    elif i['sentiment']=='負向':\n",
    "        ne+=1\n",
    "    else:\n",
    "        nu+=1\n",
    "for i in all_test:\n",
    "    if i['sentiment']=='正向':\n",
    "        po+=1\n",
    "    elif i['sentiment']=='負向':\n",
    "        ne+=1\n",
    "    else:\n",
    "        nu+=1\n",
    "print('{}\\t{}\\t{}\\t{}\\t'.format('total', round(po/(len(all_test)+len(all_train)),2), round(ne/(len(all_test)+len(all_train)),2), round(nu/(len(all_test)+len(all_train)), 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 0.17 0.53\n",
      "0.31 0.14 0.55\n"
     ]
    }
   ],
   "source": [
    "po, ne, nu = 0, 0, 0\n",
    "total = 0\n",
    "for j in train:\n",
    "    for i in j:\n",
    "        if i['sentiment']=='正向':\n",
    "            po+=1\n",
    "        elif i['sentiment']=='負向':\n",
    "            ne+=1\n",
    "        else:\n",
    "            nu+=1\n",
    "        total+=1\n",
    "print(round(po/total, 2), round(ne/total, 2), round(nu/total, 2))\n",
    "po, ne, nu = 0, 0, 0\n",
    "total=0\n",
    "for j in test:\n",
    "    for i in j:\n",
    "        if i['sentiment']=='正向':\n",
    "            po+=1\n",
    "        elif i['sentiment']=='負向':\n",
    "            ne+=1\n",
    "        else:\n",
    "            nu+=1\n",
    "        total+=1\n",
    "print(round(po/total, 2), round(ne/total, 2), round(nu/total, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Reverse Layer\n",
    "@tf.custom_gradient\n",
    "def grad_reverse(x):\n",
    "    y = tf.identity(x)\n",
    "    def custom_grad(dy):\n",
    "        return -dy\n",
    "    return y, custom_grad\n",
    "\n",
    "class GradReverse(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, x):\n",
    "        return grad_reverse(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence base, multi-task approach\n",
    "def create_classify_model(data_size, batch_size = 16, epochs=10, category_len = 8, sentiment_len = 2):\n",
    "    import model.optimization as optimization\n",
    "    input1 = Input(shape=(128,), name='input_word_ids', dtype=tf.int32)\n",
    "    input2 = Input(shape=(128,),name='input_mask', dtype=tf.int32)\n",
    "    input3 = Input(shape=(128,),name='input_type_ids', dtype=tf.int32)\n",
    "    bert_layer = hub.KerasLayer(BERT_src, trainable=True, output_key='pooled_output', name='bert_layer')\n",
    "    output = bert_layer({'input_word_ids':input1, 'input_mask':input2, 'input_type_ids':input3})\n",
    "#     output = Dense(128, name = 'presentation_')(output)\n",
    "    \n",
    "    sentiment_output = Dense(64, activation='relu', name = 'sentiment_pre', \n",
    "                             kernel_initializer=keras.initializers.glorot_normal(0), bias_initializer='zeros')(output)\n",
    "#     sentiment_output = Dropout(0.2, name='sentiment_drop')(sentiment_output)\n",
    "    sentiment_output = Dense(sentiment_len, activation='softmax', name = 'sentiment', \n",
    "                             kernel_initializer=keras.initializers.glorot_normal(0), bias_initializer='zeros')(sentiment_output) #softmax會讓所有的output總和=1\n",
    "    \n",
    "    output_model = Model(inputs = [input1, input2, input3], outputs = sentiment_output)\n",
    "    optimizer = optimization.create_optimizer(\n",
    "    5e-5, (data_size//batch_size)*epochs, int((epochs*data_size*0.1)//batch_size), 0.0, 'adamw')\n",
    "    \n",
    "    output_model.compile(optimizer=optimizer, \n",
    "                         loss={'sentiment':'categorical_crossentropy'})#'categorical_crossentropy'})\n",
    "    return output_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def sample_data_(data_list, datasize, random_=True):\n",
    "    #data_list = [BERT_x, sentiment, (category)]\n",
    "    if random_:\n",
    "        samples = random.sample(range(len(data_list[1])), datasize)\n",
    "    else:\n",
    "        samples = list(range(datasize))        \n",
    "    bert_x = data_list[0]\n",
    "    bert_x = {k:np.array([bert_x[k][i] for i in samples]) for k in bert_x.keys()}\n",
    "    sentiment = np.array(data_list[1])\n",
    "    sentiment = np.array([sentiment[i] for i in samples])\n",
    "    if len(data_list)>2:\n",
    "        category = np.array(data_list[2])\n",
    "        category = np.array([category[i] for i in samples])\n",
    "        return bert_x, sentiment, category\n",
    "    else:\n",
    "        return bert_x, sentiment\n",
    "def sample_data(data_list, datasize, random_=True):\n",
    "    #data_list = [BERT_x, sentiment]\n",
    "    if random_:\n",
    "        samples = random.sample(range(len(data_list[1])), datasize)\n",
    "    else:\n",
    "        samples = list(range(datasize))        \n",
    "    bert_x = data_list[0]\n",
    "    bert_x = {k:np.array([bert_x[k][i] for i in samples]) for k in bert_x.keys()}\n",
    "    sentiment = np.array(data_list[1])\n",
    "    sentiment = np.array([sentiment[i] for i in samples])\n",
    "    return bert_x, sentiment\n",
    "def model_get_weight(model, keyword='', not_=False):\n",
    "    origin_weight = []\n",
    "    for layer in model.layers:\n",
    "        if not_:\n",
    "            if not layer.name.startswith(keyword): \n",
    "                origin_weight.append(np.array(layer.get_weights()))\n",
    "        else:\n",
    "            if layer.name.startswith(keyword): \n",
    "                origin_weight.append(np.array(layer.get_weights()))\n",
    "    return np.array(origin_weight)\n",
    "\n",
    "def update_weights(model, update_weight, keyword='', not_=False):\n",
    "    k=0\n",
    "    for layer in model.layers:\n",
    "        if not_:\n",
    "            if not layer.name.startswith(keyword):\n",
    "                layer.set_weights(update_weight[k])\n",
    "                k+=1\n",
    "        else:\n",
    "            if layer.name.startswith(keyword):\n",
    "                layer.set_weights(update_weight[k])\n",
    "                k+=1\n",
    "def update_weights_forsame(model, model_src):\n",
    "    for layer in model.layers:\n",
    "        flag = False\n",
    "        for layer_src in model_src.layers:\n",
    "            if layer.name==layer_src.name and len(layer.get_weights())==len(layer_src.get_weights()) and flag==False:\n",
    "                try: \n",
    "                    layer.set_weights(layer_src.get_weights())\n",
    "                    flag = True\n",
    "                except:\n",
    "                    print('error!')\n",
    "        if flag==False:\n",
    "            print('model layer: \"', layer.name, '\" not in source model')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "names 這個變數是讓你可以選擇多個已訓練模型 這些模型放在 \"Meta-ACS_weight_save\" 這個資料夾\n",
    "\n",
    "meta 就是看要不要用已讀取的pretrain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "功能\n",
      "Epoch 1/7\n",
      "24/24 [==============================] - 30s 697ms/step - loss: 1.9866\n",
      "Epoch 2/7\n",
      "24/24 [==============================] - 17s 687ms/step - loss: 0.4750\n",
      "Epoch 3/7\n",
      "24/24 [==============================] - 17s 691ms/step - loss: 0.3589\n",
      "Epoch 4/7\n",
      "24/24 [==============================] - 17s 688ms/step - loss: 0.2390\n",
      "Epoch 5/7\n",
      "24/24 [==============================] - 17s 688ms/step - loss: 0.1743\n",
      "Epoch 6/7\n",
      "24/24 [==============================] - 16s 682ms/step - loss: 0.1264\n",
      "Epoch 7/7\n",
      "24/24 [==============================] - 16s 679ms/step - loss: 0.1476\n",
      "sentiment accuracy: 0.8293838862559242\n",
      "品質\n",
      "Epoch 1/7\n",
      "15/15 [==============================] - 23s 682ms/step - loss: 0.8411\n",
      "Epoch 2/7\n",
      "15/15 [==============================] - 10s 682ms/step - loss: 0.4181\n",
      "Epoch 3/7\n",
      "15/15 [==============================] - 10s 675ms/step - loss: 0.2880\n",
      "Epoch 4/7\n",
      "15/15 [==============================] - 10s 681ms/step - loss: 0.1686\n",
      "Epoch 5/7\n",
      "15/15 [==============================] - 10s 681ms/step - loss: 0.2145\n",
      "Epoch 6/7\n",
      "15/15 [==============================] - 10s 680ms/step - loss: 0.1992\n",
      "Epoch 7/7\n",
      "15/15 [==============================] - 10s 676ms/step - loss: 0.1528\n",
      "sentiment accuracy: 0.8137254901960784\n",
      "無\n",
      "Epoch 1/7\n",
      "26/26 [==============================] - 30s 658ms/step - loss: 1.5478\n",
      "Epoch 2/7\n",
      "26/26 [==============================] - 17s 659ms/step - loss: 0.6979\n",
      "Epoch 3/7\n",
      "26/26 [==============================] - 17s 660ms/step - loss: 0.4364\n",
      "Epoch 4/7\n",
      "26/26 [==============================] - 17s 660ms/step - loss: 0.2287\n",
      "Epoch 5/7\n",
      "26/26 [==============================] - 17s 660ms/step - loss: 0.1861\n",
      "Epoch 6/7\n",
      "26/26 [==============================] - 17s 658ms/step - loss: 0.1458\n",
      "Epoch 7/7\n",
      "26/26 [==============================] - 17s 659ms/step - loss: 0.1046\n",
      "sentiment accuracy: 0.694331983805668\n",
      "配件\n",
      "Epoch 1/7\n",
      "7/7 [==============================] - 19s 663ms/step - loss: 1.7242\n",
      "Epoch 2/7\n",
      "7/7 [==============================] - 5s 671ms/step - loss: 0.7699\n",
      "Epoch 3/7\n",
      "7/7 [==============================] - 5s 664ms/step - loss: 0.6600\n",
      "Epoch 4/7\n",
      "7/7 [==============================] - 5s 670ms/step - loss: 0.4688\n",
      "Epoch 5/7\n",
      "7/7 [==============================] - 5s 668ms/step - loss: 0.3705\n",
      "Epoch 6/7\n",
      "7/7 [==============================] - 5s 675ms/step - loss: 0.2888\n",
      "Epoch 7/7\n",
      "7/7 [==============================] - 5s 671ms/step - loss: 0.2223\n",
      "sentiment accuracy: 0.6987951807228916\n",
      "售後\n",
      "Epoch 1/7\n",
      "5/5 [==============================] - 18s 629ms/step - loss: 1.1381\n",
      "Epoch 2/7\n",
      "5/5 [==============================] - 3s 633ms/step - loss: 0.7626\n",
      "Epoch 3/7\n",
      "5/5 [==============================] - 3s 640ms/step - loss: 0.4379\n",
      "Epoch 4/7\n",
      "5/5 [==============================] - 3s 635ms/step - loss: 0.2804\n",
      "Epoch 5/7\n",
      "5/5 [==============================] - 3s 625ms/step - loss: 0.1250\n",
      "Epoch 6/7\n",
      "5/5 [==============================] - 3s 628ms/step - loss: 0.0653\n",
      "Epoch 7/7\n",
      "5/5 [==============================] - 3s 628ms/step - loss: 0.0520\n",
      "sentiment accuracy: 0.7\n",
      "外觀\n",
      "Epoch 1/7\n",
      "5/5 [==============================] - 15s 599ms/step - loss: 2.4174\n",
      "Epoch 2/7\n",
      "5/5 [==============================] - 3s 596ms/step - loss: 0.6980\n",
      "Epoch 3/7\n",
      "5/5 [==============================] - 3s 593ms/step - loss: 0.6246\n",
      "Epoch 4/7\n",
      "5/5 [==============================] - 3s 600ms/step - loss: 0.3852\n",
      "Epoch 5/7\n",
      "5/5 [==============================] - 3s 598ms/step - loss: 0.2542\n",
      "Epoch 6/7\n",
      "5/5 [==============================] - 3s 599ms/step - loss: 0.2156\n",
      "Epoch 7/7\n",
      "5/5 [==============================] - 3s 597ms/step - loss: 0.1701\n",
      "sentiment accuracy: 0.6666666666666666\n",
      "價位\n",
      "Epoch 1/7\n",
      "4/4 [==============================] - 15s 564ms/step - loss: 1.9247\n",
      "Epoch 2/7\n",
      "4/4 [==============================] - 2s 570ms/step - loss: 0.7865\n",
      "Epoch 3/7\n",
      "4/4 [==============================] - 2s 565ms/step - loss: 0.5714\n",
      "Epoch 4/7\n",
      "4/4 [==============================] - 2s 566ms/step - loss: 0.3173\n",
      "Epoch 5/7\n",
      "4/4 [==============================] - 2s 566ms/step - loss: 0.2482\n",
      "Epoch 6/7\n",
      "4/4 [==============================] - 2s 558ms/step - loss: 0.1824\n",
      "Epoch 7/7\n",
      "4/4 [==============================] - 2s 566ms/step - loss: 0.2138\n",
      "WARNING:tensorflow:5 out of the last 25 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f50f2840598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 25 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f50f2840598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment accuracy: 0.5714285714285714\n",
      "音量\n",
      "Epoch 1/7\n",
      "2/2 [==============================] - 14s 646ms/step - loss: 0.8670\n",
      "Epoch 2/7\n",
      "2/2 [==============================] - 1s 643ms/step - loss: 0.2305\n",
      "Epoch 3/7\n",
      "2/2 [==============================] - 1s 644ms/step - loss: 0.1475\n",
      "Epoch 4/7\n",
      "2/2 [==============================] - 1s 632ms/step - loss: 0.0978\n",
      "Epoch 5/7\n",
      "2/2 [==============================] - 1s 651ms/step - loss: 0.1194\n",
      "Epoch 6/7\n",
      "2/2 [==============================] - 1s 639ms/step - loss: 0.1057\n",
      "Epoch 7/7\n",
      "2/2 [==============================] - 1s 637ms/step - loss: 0.1804\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f50f0dfe7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f50f0dfe7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment accuracy: 0.5675675675675675\n",
      "overall:\n",
      "sentiment f1 score(ma-micro): 0.692737418330421\n",
      "sentiment accuracy: 0.7419127988748242\n",
      "sentiment f1 score(macro): 0.6858271942305555\n",
      "sentiment f1 score(micro): 0.7419127988748242\n",
      "sentiment f1 score(weight): 0.7354685732783807\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          中立       0.78      0.87      0.83       788\n",
      "          正向       0.69      0.58      0.63       441\n",
      "          負向       0.64      0.56      0.60       193\n",
      "\n",
      "    accuracy                           0.74      1422\n",
      "   macro avg       0.70      0.67      0.69      1422\n",
      "weighted avg       0.74      0.74      0.74      1422\n",
      "\n",
      "-------------------\n",
      "1\n",
      "功能\n",
      "Epoch 1/7\n",
      "24/24 [==============================] - 31s 676ms/step - loss: 2.0796\n",
      "Epoch 2/7\n",
      "24/24 [==============================] - 16s 676ms/step - loss: 0.4759\n",
      "Epoch 3/7\n",
      "24/24 [==============================] - 16s 672ms/step - loss: 0.3665\n",
      "Epoch 4/7\n",
      "24/24 [==============================] - 16s 675ms/step - loss: 0.2987\n",
      "Epoch 5/7\n",
      "24/24 [==============================] - 16s 676ms/step - loss: 0.1673\n",
      "Epoch 6/7\n",
      "24/24 [==============================] - 16s 674ms/step - loss: 0.1537\n",
      "Epoch 7/7\n",
      "24/24 [==============================] - 16s 673ms/step - loss: 0.1267\n",
      "WARNING:tensorflow:6 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f504f9488c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f504f9488c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment accuracy: 0.8341232227488151\n",
      "品質\n",
      "Epoch 1/7\n",
      "15/15 [==============================] - 25s 663ms/step - loss: 0.9317\n",
      "Epoch 2/7\n",
      "15/15 [==============================] - 10s 660ms/step - loss: 0.4260\n",
      "Epoch 3/7\n",
      "15/15 [==============================] - 10s 661ms/step - loss: 0.3148\n",
      "Epoch 4/7\n",
      "15/15 [==============================] - 10s 664ms/step - loss: 0.3018\n",
      "Epoch 5/7\n",
      "15/15 [==============================] - 10s 662ms/step - loss: 0.3762\n",
      "Epoch 6/7\n",
      "15/15 [==============================] - 10s 662ms/step - loss: 0.2050\n",
      "Epoch 7/7\n",
      "15/15 [==============================] - 10s 663ms/step - loss: 0.1154\n",
      "sentiment accuracy: 0.8333333333333334\n",
      "無\n",
      "Epoch 1/7\n",
      "26/26 [==============================] - 30s 663ms/step - loss: 1.5635\n",
      "Epoch 2/7\n",
      "26/26 [==============================] - 17s 662ms/step - loss: 0.6747\n",
      "Epoch 3/7\n",
      "26/26 [==============================] - 17s 660ms/step - loss: 0.5026\n",
      "Epoch 4/7\n",
      "26/26 [==============================] - 17s 663ms/step - loss: 0.3083\n",
      "Epoch 5/7\n",
      "26/26 [==============================] - 17s 662ms/step - loss: 0.2177\n",
      "Epoch 6/7\n",
      "26/26 [==============================] - 17s 660ms/step - loss: 0.2215\n",
      "Epoch 7/7\n",
      "26/26 [==============================] - 17s 664ms/step - loss: 0.1575\n",
      "sentiment accuracy: 0.6821862348178138\n",
      "配件\n",
      "Epoch 1/7\n",
      "7/7 [==============================] - 17s 652ms/step - loss: 1.7562\n",
      "Epoch 2/7\n",
      "7/7 [==============================] - 5s 658ms/step - loss: 0.7245\n",
      "Epoch 3/7\n",
      "7/7 [==============================] - 5s 655ms/step - loss: 0.5005\n",
      "Epoch 4/7\n",
      "7/7 [==============================] - 5s 657ms/step - loss: 0.5128\n",
      "Epoch 5/7\n",
      "7/7 [==============================] - 5s 654ms/step - loss: 0.3214\n",
      "Epoch 6/7\n",
      "7/7 [==============================] - 5s 656ms/step - loss: 0.3130\n",
      "Epoch 7/7\n",
      "7/7 [==============================] - 5s 661ms/step - loss: 0.1833\n",
      "sentiment accuracy: 0.6867469879518072\n",
      "售後\n",
      "Epoch 1/7\n",
      "5/5 [==============================] - 16s 636ms/step - loss: 1.2366\n",
      "Epoch 2/7\n",
      "5/5 [==============================] - 3s 633ms/step - loss: 0.7921\n",
      "Epoch 3/7\n",
      "5/5 [==============================] - 3s 635ms/step - loss: 0.4630\n",
      "Epoch 4/7\n",
      "5/5 [==============================] - 3s 635ms/step - loss: 0.3623\n",
      "Epoch 5/7\n",
      "5/5 [==============================] - 3s 638ms/step - loss: 0.2078\n",
      "Epoch 6/7\n",
      "5/5 [==============================] - 3s 635ms/step - loss: 0.1110\n",
      "Epoch 7/7\n",
      "5/5 [==============================] - 3s 631ms/step - loss: 0.1018\n",
      "sentiment accuracy: 0.78\n",
      "外觀\n",
      "Epoch 1/7\n",
      "5/5 [==============================] - 18s 609ms/step - loss: 2.4500\n",
      "Epoch 2/7\n",
      "5/5 [==============================] - 3s 612ms/step - loss: 0.7093\n",
      "Epoch 3/7\n",
      "5/5 [==============================] - 3s 609ms/step - loss: 0.4950\n",
      "Epoch 4/7\n",
      "5/5 [==============================] - 3s 610ms/step - loss: 0.3472\n",
      "Epoch 5/7\n",
      "5/5 [==============================] - 3s 610ms/step - loss: 0.1860\n",
      "Epoch 6/7\n",
      "5/5 [==============================] - 3s 609ms/step - loss: 0.1592\n",
      "Epoch 7/7\n",
      "5/5 [==============================] - 3s 610ms/step - loss: 0.1140\n",
      "sentiment accuracy: 0.7246376811594203\n",
      "價位\n",
      "Epoch 1/7\n",
      "4/4 [==============================] - 15s 584ms/step - loss: 1.6564\n",
      "Epoch 2/7\n",
      "4/4 [==============================] - 2s 589ms/step - loss: 0.9661\n",
      "Epoch 3/7\n",
      "4/4 [==============================] - 2s 581ms/step - loss: 0.7586\n",
      "Epoch 4/7\n",
      "4/4 [==============================] - 2s 579ms/step - loss: 0.4342\n",
      "Epoch 5/7\n",
      "4/4 [==============================] - 2s 580ms/step - loss: 0.2863\n",
      "Epoch 6/7\n",
      "4/4 [==============================] - 2s 582ms/step - loss: 0.2364\n",
      "Epoch 7/7\n",
      "4/4 [==============================] - 2s 586ms/step - loss: 0.2635\n",
      "WARNING:tensorflow:5 out of the last 25 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f504f9768c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 25 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f504f9768c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment accuracy: 0.5873015873015873\n",
      "音量\n",
      "Epoch 1/7\n",
      "2/2 [==============================] - 14s 635ms/step - loss: 1.0629\n",
      "Epoch 2/7\n",
      "2/2 [==============================] - 1s 633ms/step - loss: 0.5364\n",
      "Epoch 3/7\n",
      "2/2 [==============================] - 1s 636ms/step - loss: 0.1918\n",
      "Epoch 4/7\n",
      "2/2 [==============================] - 1s 623ms/step - loss: 0.0878\n",
      "Epoch 5/7\n",
      "2/2 [==============================] - 1s 631ms/step - loss: 0.0833\n",
      "Epoch 6/7\n",
      "2/2 [==============================] - 1s 637ms/step - loss: 0.1161\n",
      "Epoch 7/7\n",
      "2/2 [==============================] - 1s 643ms/step - loss: 0.1125\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f504cd0d950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f504cd0d950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment accuracy: 0.5135135135135135\n",
      "overall:\n",
      "sentiment f1 score(ma-micro): 0.7052303201032863\n",
      "sentiment accuracy: 0.7461322081575246\n",
      "sentiment f1 score(macro): 0.6926535620293874\n",
      "sentiment f1 score(micro): 0.7461322081575245\n",
      "sentiment f1 score(weight): 0.7415790656971359\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          中立       0.80      0.86      0.83       788\n",
      "          正向       0.69      0.61      0.65       441\n",
      "          負向       0.63      0.58      0.60       193\n",
      "\n",
      "    accuracy                           0.75      1422\n",
      "   macro avg       0.70      0.68      0.69      1422\n",
      "weighted avg       0.74      0.75      0.74      1422\n",
      "\n",
      "-------------------\n",
      "2\n",
      "功能\n"
     ]
    },
    {
     "ename": "DataLossError",
     "evalue": "TensorBundle at /tmp/tfhub_modules/be4cff0fcfe466313112ea7bc4d88770583b60b6/variables/variables shard 0 (64905216 bytes): Checksum does not match: stored 114360999 vs. calculated on the restored bytes 2314620158 [Op:RestoreV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mDataLossError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-05ff8bde37c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_data_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtmp_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_sentiment\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_sentiment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/cpu:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_classify_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentiment_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mupdate_weights_forsame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-7730546cbd70>\u001b[0m in \u001b[0;36mcreate_classify_model\u001b[0;34m(data_size, batch_size, epochs, category_len, sentiment_len)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0minput2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'input_mask'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0minput3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'input_type_ids'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mbert_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBERT_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pooled_output'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bert_layer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'input_word_ids'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'input_mask'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0minput2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'input_type_ids'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0minput3\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#     output = Dense(128, name = 'presentation_')(output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_hub/keras_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, handle, trainable, arguments, _sentinel, tags, signature, signature_outputs_as_dict, output_key, output_shape, load_options, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_training_argument\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_has_training_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_hub_module_v1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_is_hub_module_v1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_hub/keras_layer.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(handle, tags, load_options)\u001b[0m\n\u001b[1;32m    447\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Expected before TF2.4.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0mset_load_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodule_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mset_load_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_hub/module_v2.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(handle, tags, options)\u001b[0m\n\u001b[1;32m    104\u001b[0m         module_path, tags=tags, options=options)\n\u001b[1;32m    105\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m   \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_hub_module_v1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_hub_module_v1\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(export_dir, tags, options)\u001b[0m\n\u001b[1;32m    857\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mdon\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0ma\u001b[0m \u001b[0mMetaGraph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mSavedModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m   \"\"\"\n\u001b[0;32m--> 859\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mload_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"root\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload_internal\u001b[0;34m(export_dir, tags, options, loader_cls, filters)\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         loader = loader_cls(object_graph_proto, saved_model_proto, export_dir,\n\u001b[0;32m--> 890\u001b[0;31m                             ckpt_options, filters)\n\u001b[0m\u001b[1;32m    891\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m         raise FileNotFoundError(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, object_graph_proto, saved_model_proto, export_dir, ckpt_options, filters)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restore_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36m_restore_checkpoint\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    485\u001b[0m                                   self._checkpoint_options).expect_partial()\n\u001b[1;32m    486\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0mload_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0mload_status\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_existing_objects_matched\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_status\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, save_path, options)\u001b[0m\n\u001b[1;32m   1335\u001b[0m         options=options)\n\u001b[1;32m   1336\u001b[0m     base.CheckpointPosition(\n\u001b[0;32m-> 1337\u001b[0;31m         checkpoint=checkpoint, proto_id=0).restore(self._graph_view.root)\n\u001b[0m\u001b[1;32m   1338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m     \u001b[0;31m# Attached dependencies are not attached to the root, so should be restored\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, trackable)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;31m# This object's correspondence with a checkpointed object is new, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;31m# process deferred restorations for it and its dependencies.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mrestore_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restore_from_checkpoint_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_restore_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestore_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_restore_from_checkpoint_position\u001b[0;34m(self, checkpoint_position)\u001b[0m\n\u001b[1;32m    971\u001b[0m     restore_ops.extend(\n\u001b[1;32m    972\u001b[0m         current_position.checkpoint.restore_saveables(\n\u001b[0;32m--> 973\u001b[0;31m             tensor_saveables, python_saveables))\n\u001b[0m\u001b[1;32m    974\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36mrestore_saveables\u001b[0;34m(self, tensor_saveables, python_saveables)\u001b[0m\n\u001b[1;32m    306\u001b[0m              \"expecting %s\") % (tensor_saveables.keys(), validated_names))\n\u001b[1;32m    307\u001b[0m       new_restore_ops = functional_saver.MultiDeviceSaver(\n\u001b[0;32m--> 308\u001b[0;31m           validated_saveables).restore(self.save_path_tensor, self.options)\n\u001b[0m\u001b[1;32m    309\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_op\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_restore_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, file_prefix, options)\u001b[0m\n\u001b[1;32m    343\u001b[0m       \u001b[0mrestore_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_function_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m       \u001b[0mrestore_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_restore_callbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36mrestore_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m    319\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaver\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_single_device_savers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m           \u001b[0mrestore_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, file_prefix, options)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestore_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m       restored_tensors = io_ops.restore_v2(\n\u001b[0;32m--> 109\u001b[0;31m           file_prefix, tensor_names, tensor_slices, tensor_dtypes)\n\u001b[0m\u001b[1;32m    110\u001b[0m     structured_restored_tensors = nest.pack_sequence_as(\n\u001b[1;32m    111\u001b[0m         tensor_structure, restored_tensors)\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36mrestore_v2\u001b[0;34m(prefix, tensor_names, shape_and_slices, dtypes, name)\u001b[0m\n\u001b[1;32m   1497\u001b[0m       return restore_v2_eager_fallback(\n\u001b[1;32m   1498\u001b[0m           \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_and_slices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1499\u001b[0;31m           ctx=_ctx)\n\u001b[0m\u001b[1;32m   1500\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36mrestore_v2_eager_fallback\u001b[0;34m(prefix, tensor_names, shape_and_slices, dtypes, name, ctx)\u001b[0m\n\u001b[1;32m   1535\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"dtypes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m   _result = _execute.execute(b\"RestoreV2\", len(dtypes), inputs=_inputs_flat,\n\u001b[0;32m-> 1537\u001b[0;31m                              attrs=_attrs, ctx=ctx, name=name)\n\u001b[0m\u001b[1;32m   1538\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m     _execute.record_gradient(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDataLossError\u001b[0m: TensorBundle at /tmp/tfhub_modules/be4cff0fcfe466313112ea7bc4d88770583b60b6/variables/variables shard 0 (64905216 bytes): Checksum does not match: stored 114360999 vs. calculated on the restored bytes 2314620158 [Op:RestoreV2]"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "import model.optimization as optimization\n",
    "data_size=1000\n",
    "batch_size=32\n",
    "epochs=7\n",
    "optimizer = optimization.create_optimizer(5e-5, (data_size//batch_size)*epochs, int((epochs*data_size*0.1)//batch_size), 0.0, 'adamw')\n",
    "meta = True\n",
    "names = ['rep_adv_opt_lamb.h5'] #pre-trained model choice\n",
    "mamicros = []\n",
    "total_micros = []\n",
    "for name in names:\n",
    "    sent_pred_total, sent_ans_total = [], []\n",
    "    tmp_model = load_model('./Meta-ACS_weight_save/'+name, custom_objects={'KerasLayer':BERT_LAYER, 'AdamWeightDecay':optimizer})\n",
    "    for itr in range(5):\n",
    "        mamicro = []\n",
    "        total_pred, total_ans = [], []\n",
    "        print(itr)\n",
    "        for c in range(len(category)):\n",
    "            print(category[c])\n",
    "            epochs=7\n",
    "            tmp_train, train_sentiment = BERTdata2Traindata(train[c], to_cate=True, objective=['sentiment'])\n",
    "            tmp_test, test_sentiment = BERTdata2Traindata(test[c], to_cate=True, objective=['sentiment'])\n",
    "            x, sent = sample_data_([tmp_train, train_sentiment], datasize=len(train_sentiment),random_=False)\n",
    "            with tf.device('/cpu:0'):\n",
    "                model = create_classify_model(data_size=len(sent), epochs=epochs, sentiment_len = 3)\n",
    "            if meta:\n",
    "                update_weights_forsame(model, tmp_model)                \n",
    "            history = model.fit(x, sent, batch_size=16, epochs=epochs, verbose=1)\n",
    "            sent_pred = model.predict([np.array(tmp_test['input_word_ids']), \n",
    "                            np.array(tmp_test['input_mask']),\n",
    "                            np.array(tmp_test['input_type_ids'])])\n",
    "            sent_predict = [idx2sent[np.argmax(i)] for i in sent_pred]\n",
    "            sent_ans = [idx2sent[np.argmax(i)] for i in test_sentiment]\n",
    "            total_pred+=sent_predict\n",
    "            total_ans+=sent_ans\n",
    "            mamicro.append(f1_score(sent_ans, sent_predict, average='micro'))\n",
    "#             print('category:', category[c])\n",
    "            print('sentiment accuracy:',accuracy_score(sent_ans, sent_predict))\n",
    "#             print('sentiment f1 score(macro):', f1_score(sent_ans, sent_predict, average='macro'))\n",
    "#             print('sentiment f1 score(micro):', f1_score(sent_ans, sent_predict, average='micro'))\n",
    "#             print('sentiment f1 score(weight):', f1_score(sent_ans, sent_predict, average='weighted'))\n",
    "#             print(classification_report(sent_ans, sent_predict))\n",
    "#             print('-------------------')\n",
    "            del model, tmp_train, tmp_test, train_sentiment, test_sentiment\n",
    "        print('overall:')\n",
    "        print('sentiment f1 score(ma-micro):', np.mean(mamicro))\n",
    "        print('sentiment accuracy:',accuracy_score(total_ans, total_pred))\n",
    "        print('sentiment f1 score(macro):', f1_score(total_ans, total_pred, average='macro'))\n",
    "        print('sentiment f1 score(micro):', f1_score(total_ans, total_pred, average='micro'))\n",
    "        print('sentiment f1 score(weight):', f1_score(total_ans, total_pred, average='weighted'))\n",
    "        print(classification_report(total_ans, total_pred))\n",
    "        print('-------------------')\n",
    "        sent_pred_total+=total_pred\n",
    "        sent_ans_total+=total_ans\n",
    "        mamicros.append(np.mean(mamicro))\n",
    "        total_micros.append(f1_score(total_ans, total_pred, average='micro'))\n",
    "#         np.save('./predict_result/'+name[:-3]+'_multiple_more.npy', sent_pred_total)\n",
    "        #['功能', '品質', '無', '配件', '售後', '外觀', '價位', '音量']\n",
    "        np.save('./predict_result/'+name[:-3]+'_multiple.npy', sent_pred_total)\n",
    "    try:\n",
    "        del tmp_model\n",
    "    except:\n",
    "        ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 422, 626, 1120, 1203, 1253, 1322, 1385, 1422]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cate_split = [0]\n",
    "for c in range(len(category)):\n",
    "    tmp_test, test_sentiment = BERTdata2Traindata(test[c], to_cate=True, objective=['sentiment'])\n",
    "    cate_split.append(cate_split[-1]+len(test_sentiment))\n",
    "cate_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#這邊看你要用的預測結果是剛剛跑出來的 還是之前已經存好的\n",
    "\n",
    "#之前存好的\n",
    "#mypred = np.load('./predict_result/dann_multiple.npy')\n",
    "#剛剛跑出來的\n",
    "mypred = sent_pred_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total-micro 0.7257383966244725\n",
      "ma-micro 0.6324329086588832\n"
     ]
    }
   ],
   "source": [
    "#multiple\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "cate_split = [0, 422, 626, 1120, 1203, 1253, 1322, 1385, 1422]\n",
    "\n",
    "myans = [i['sentiment'] for i in all_test]*5\n",
    "category_perf = {_:[] for _ in category}\n",
    "macros = []\n",
    "for i in range(5):\n",
    "    macro = []\n",
    "    start = int(i*1422)\n",
    "    for c in range(len(category)):\n",
    "        predicts = mypred[start+cate_split[c]:start+cate_split[c+1]]\n",
    "        answers = myans[start+cate_split[c]:start+cate_split[c+1]]\n",
    "        macro.append(f1_score(answers, predicts, average='micro'))\n",
    "#         print(category[c])\n",
    "#         print('sentiment f1 score(macro):', f1_score(answers, predicts, average='macro'))\n",
    "#         print('sentiment f1 score(micro):', f1_score(answers, predicts, average='micro'))\n",
    "        category_perf[category[c]].append(f1_score(answers, predicts, average='micro'))\n",
    "    macros.append(np.mean(macro))\n",
    "micro = []\n",
    "for i in range(5):\n",
    "    macro = []\n",
    "    start = int(i*1422)\n",
    "    predicts = mypred[start:start+1422]\n",
    "    answers = myans[start:start+1422]\n",
    "    micro.append(f1_score(answers, predicts, average='micro'))\n",
    "\n",
    "# print(macros)\n",
    "print('micro', np.mean(micro))\n",
    "print('macro',np.mean(macros))\n",
    "#print(category_perf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 統計數據"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "信賴區間、每個實驗的數據(在每個aspect category中的sentiment f1 score)\n",
    "\n",
    "總之這邊有沒有看其實沒差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "功能 的信賴區間 0.018170890533346792\n",
      "品質 的信賴區間 0.03053414020077924\n",
      "無 的信賴區間 0.012930137184349239\n",
      "配件 的信賴區間 0.03959440174736142\n",
      "售後 的信賴區間 0.043817804600413325\n",
      "外觀 的信賴區間 0.03304856304635183\n",
      "價位 的信賴區間 0.028394513999997317\n",
      "音量 的信賴區間 0.09044973259827843\n",
      "micro的單側信賴區間: 0.010784973002914642\n",
      "macro的單側信賴區間: 0.00868209932538389\n"
     ]
    }
   ],
   "source": [
    "for i in category:\n",
    "    print(i,'的信賴區間',np.std([_*1 for _ in category_perf[i]], ddof=1)*2)\n",
    "print('micro的單側信賴區間:',np.std([_*1 for _ in micro], ddof=1)*2)\n",
    "print('macro的單側信賴區間:',np.std([_*1 for _ in macros], ddof=1)*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ma-micro\n",
      "0.6905102557221909\n",
      "positive\n",
      "{'功能': 0.40258436019163935, '品質': 0.8701903643384081, '無': 0.5471333553757458, '配件': 0.56772444946358, '售後': 0.6944807965860595, '外觀': 0.25819548872180453, '價位': 0.6345188104701782, '音量': 0.5987468671679198}\n",
      "negative\n",
      "{'功能': 0.028571428571428574, '品質': 0.8151485094631956, '無': 0.3115720021938542, '配件': 0.8099206349206349, '售後': 0.6955038759689923, '外觀': 0.20969696969696966, '價位': 0.39604554865424435, '音量': 0.5620677361853832}\n",
      "neutral\n",
      "{'功能': 0.9117929847996477, '品質': 0.07999999999999999, '無': 0.7863647203172357, '配件': 0.7654563449930448, '售後': 0.3332323232323232, '外觀': 0.8291805460029759, '價位': 0.6368816368816369, '音量': 0.0}\n",
      "micro f1 score\n",
      "{'功能': 0.842654028436019, '品質': 0.8323529411764706, '無': 0.682591093117409, '配件': 0.710843373493976, '售後': 0.62, '外觀': 0.7014492753623188, '價位': 0.5936507936507937, '音量': 0.5405405405405406}\n",
      "weighted f1 score\n",
      "{'功能': 0.8061521297510993, '品質': 0.8153628616922738, '無': 0.6671204965266121, '配件': 0.7078019478322574, '售後': 0.5937199942125279, '外觀': 0.626359785294322, '價位': 0.597603541297593, '音量': 0.5049478661243367}\n",
      "positive:0.6415439747307133\n",
      "neutral:0.826236363417841\n",
      "negative:0.5919172676712318\n",
      "micro:0.7443037974683543\n",
      "macro:0.6865658686065953\n",
      "weighted:0.7371555414135378\n"
     ]
    }
   ],
   "source": [
    "#single\n",
    "import numpy as np\n",
    "temp = np.load('./predict_result/reptile_single.npy')\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report, precision_recall_fscore_support\n",
    "mamicro = []\n",
    "category_wf = {_:0 for _ in category}\n",
    "category_perf = {_:0 for _ in category}\n",
    "category_po, category_ne, category_nu = {_:0 for _ in category}, {_:0 for _ in category}, {_:0 for _ in category} \n",
    "for i in range(5):\n",
    "    micro = []\n",
    "    for j in category:\n",
    "        pred, ans = [], []\n",
    "        for k in range(1422):\n",
    "            if BERT_test[k]['target'].split('-')[1]==j:\n",
    "                pred.append(temp[i*1422+k])\n",
    "                ans.append(BERT_test[k]['sentiment'])\n",
    "        for label in ['正向', '負向', '中立']:\n",
    "            p = [1 if l==label else 0 for l in pred]\n",
    "            a = [1 if l==label else 0 for l in ans]\n",
    "            if label=='正向':\n",
    "                category_po[j]+=f1_score(a, p, average='binary')\n",
    "            elif label=='負向':\n",
    "                category_ne[j]+=f1_score(a, p, average='binary')\n",
    "            else:\n",
    "                category_nu[j]+=f1_score(a, p, average='binary')\n",
    "\n",
    "        micro.append(f1_score(ans, pred, average='micro'))\n",
    "        category_perf[j]+=f1_score(ans, pred, average='micro')\n",
    "        category_wf[j]+=f1_score(ans, pred, average='weighted')\n",
    "    mamicro.append(np.mean(micro))\n",
    "for c in category:\n",
    "    category_perf[c]/=5\n",
    "    category_po[c]/=5\n",
    "    category_ne[c]/=5\n",
    "    category_nu[c]/=5\n",
    "    category_wf[c]/=5\n",
    "print('ma-micro')\n",
    "print(np.mean(mamicro))\n",
    "print('positive')\n",
    "print(category_po)\n",
    "\n",
    "print('negative')\n",
    "print(category_ne)\n",
    "\n",
    "print('neutral')\n",
    "print(category_nu)\n",
    "\n",
    "print('micro f1 score')\n",
    "print(category_perf)\n",
    "\n",
    "print('weighted f1 score')\n",
    "print(category_wf)\n",
    "pof, nef, nuf, totalmif, totalmaf, totalwef = 0, 0, 0, 0, 0, 0\n",
    "for i in range(5):\n",
    "    pred=temp[i*1422:i*1422+1422]\n",
    "    ans = [BERT_test[i]['sentiment'] for i in range(len(all_test)) ]   \n",
    "    totalmif+=f1_score(ans, pred, average='micro')\n",
    "    totalmaf+=f1_score(ans, pred, average='macro')\n",
    "    totalwef+=f1_score(ans, pred, average='weighted')\n",
    "    for label in ['正向', '負向', '中立']:\n",
    "        p = [1 if l==label else 0 for l in pred]\n",
    "        a = [1 if l==label else 0 for l in ans]\n",
    "        if label=='正向':\n",
    "            pof+=f1_score(a, p, average='binary')\n",
    "        elif label=='負向':\n",
    "            nef+=f1_score(a, p, average='binary')\n",
    "        else:\n",
    "            nuf+=f1_score(a, p, average='binary')\n",
    "print('positive:{}\\nneutral:{}\\nnegative:{}\\nmicro:{}\\nmacro:{}\\nweighted:{}'.format(pof/5, nuf/5, nef/5, totalmif/5, totalmaf/5, totalwef/5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
